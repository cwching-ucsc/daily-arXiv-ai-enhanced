{"id": "2510.22909", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.22909", "abs": "https://arxiv.org/abs/2510.22909", "authors": ["Zongshun Zhang", "Ibrahim Matta"], "title": "Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions", "comment": null, "summary": "Edge intelligent applications like VR/AR and language model based chatbots\nhave become widespread with the rapid expansion of IoT and mobile devices.\nHowever, constrained edge devices often cannot serve the increasingly large and\ncomplex deep learning (DL) models. To mitigate these challenges, researchers\nhave proposed optimizing and offloading partitions of DL models among user\ndevices, edge servers, and the cloud. In this setting, users can take advantage\nof different services to support their intelligent applications. For example,\nedge resources offer low response latency. In contrast, cloud platforms provide\nlow monetary cost computation resources for computation-intensive workloads.\nHowever, communication between DL model partitions can introduce transmission\nbottlenecks and pose risks of data leakage. Recent research aims to balance\naccuracy, computation delay, transmission delay, and privacy concerns. They\naddress these issues with model compression, model distillation, transmission\ncompression, and model architecture adaptations, including internal\nclassifiers. This survey contextualizes the state-of-the-art model offloading\nmethods and model adaptation techniques by studying their implication to a\nmulti-objective optimization comprising inference latency, data privacy, and\nresource monetary cost.", "AI": {"tldr": "Survey of model partitioning/offloading for edge intelligent applications, examining trade-offs among inference latency, data privacy, and monetary cost; covers techniques like model compression, distillation, transmission compression, and internal classifiers.", "motivation": "Edge and mobile devices are resource-constrained yet must support large DL models for VR/AR and chatbots; partitioning/offloading among device, edge, and cloud can leverage complementary resources but introduces latency, bandwidth, and privacy trade-offs.", "method": "A literature survey that categorizes and contextualizes state-of-the-art offloading and model adaptation techniques, and analyzes their implications within a multi-objective optimization framework balancing latency, privacy, and cost.", "result": "Provides a taxonomy of approaches (offloading strategies, compression/distillation, architecture adaptations), highlights transmission bottlenecks and privacy risks, and synthesizes how methods trade accuracy, delay, and cost.", "conclusion": "Concludes that existing methods partially address trade-offs but gaps remain; calls for multi-objective optimization, standardized benchmarks, and research into adaptive, privacy-preserving, and cost-aware partitioning strategies."}}
{"id": "2510.23503", "categories": ["cs.DC", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23503", "abs": "https://arxiv.org/abs/2510.23503", "authors": ["Fatemeh Zahra Safaeipour", "Jacob Chakareski", "Morteza Hashemi"], "title": "Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems", "comment": null, "summary": "Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely\ninference tasks while operating with limited on-board computing and energy\nresources. In this paper, we investigate the problem of collaborative inference\nin wireless edge networks, where energy-constrained edge devices aim to\ncomplete inference tasks within given deadlines. These tasks are carried out\nusing neural networks, and the edge device seeks to optimize inference\nperformance under energy and delay constraints. The inference process can be\nsplit between the edge device and an edge server, thereby achieving\ncollaborative inference over wireless networks. We formulate an inference\nutility optimization problem subject to energy and delay constraints, and\npropose a novel solution called Bayes-Split-Edge, which leverages Bayesian\noptimization for collaborative split inference over wireless edge networks. Our\nsolution jointly optimizes the transmission power and the neural network split\npoint. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition\nfunction that balances inference task utility, sample efficiency, and\nconstraint violation penalties. We evaluate our approach using the VGG19 model\non the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world\nmMobile wireless channel datasets. Numerical results demonstrate that\nBayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to\nstandard Bayesian optimization and achieves near-linear convergence. It also\noutperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and\nProximal Policy Optimization (PPO), while matching exhaustive search\nperformance under tight constraints. These results confirm that the proposed\nframework provides a sample-efficient solution requiring maximum 20 function\nevaluations and constraint-aware optimization for wireless split inference in\nedge computing systems.", "AI": {"tldr": "Presents Bayes-Split-Edge, a constrained Bayesian optimization framework that jointly selects neural-network split point and transmission power for wireless collaborative inference under energy and deadline constraints; shows sample-efficient, constraint-aware optimization with strong empirical gains (\u226420 evaluations, up to 2.4\u00d7 lower cost vs standard BO) on VGG19/ResNet101 and real wireless traces.", "motivation": "Edge devices (AR/VR, etc.) have tight compute/energy budgets yet must meet inference latency deadlines. Splitting inference between device and edge server over wireless links can trade computation and communication, but finding the optimal split and transmit power under energy and delay constraints is nontrivial and costly to evaluate directly.", "method": "Formulates an inference-utility optimization with energy and delay constraints. Proposes Bayes-Split-Edge: a constrained Bayesian optimization that jointly optimizes transmit power and network split point. Introduces a hybrid acquisition function to balance task utility, sample efficiency, and penalties for constraint violations.", "result": "Evaluated on ImageNet-Mini with VGG19 and Tiny-ImageNet with ResNet101 using real mobile wireless channel traces. Reported up to 2.4\u00d7 reduction in evaluation cost vs standard BO, near-linear convergence, outperformance of CMA-ES, DIRECT, exhaustive search, and PPO, and matching exhaustive search under tight constraints, while requiring at most 20 function evaluations.", "conclusion": "Bayes-Split-Edge is a sample-efficient, constraint-aware approach for wireless split inference that can find near-optimal split-and-power settings with few evaluations and robust performance under realistic channel conditions."}}
{"id": "2510.22397", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22397", "abs": "https://arxiv.org/abs/2510.22397", "authors": ["Satyandra Guthula", "Jaber Daneshamooz", "Charles Fleming", "Ashish Kundu", "Walter Willinger", "Arpit Gupta"], "title": "NetBurst: Event-Centric Forecasting of Bursty, Intermittent Time Series", "comment": null, "summary": "Forecasting on widely used benchmark time series data (e.g., ETT,\nElectricity, Taxi, and Exchange Rate, etc.) has favored smooth, seasonal\nseries, but network telemetry time series -- traffic measurements at service,\nIP, or subnet granularity -- are instead highly bursty and intermittent, with\nheavy-tailed bursts and highly variable inactive periods. These properties\nplace the latter in the statistical regimes made famous and popularized more\nthan 20 years ago by B.~Mandelbrot. Yet forecasting such time series with\nmodern-day AI architectures remains underexplored. We introduce NetBurst, an\nevent-centric framework that reformulates forecasting as predicting when bursts\noccur and how large they are, using quantile-based codebooks and dual\nautoregressors. Across large-scale sets of production network telemetry time\nseries and compared to strong baselines, such as Chronos, NetBurst reduces Mean\nAverage Scaled Error (MASE) by 13--605x on service-level time series while\npreserving burstiness and producing embeddings that cluster 5x more cleanly\nthan Chronos. In effect, our work highlights the benefits that modern AI can\nreap from leveraging Mandelbrot's pioneering studies for forecasting in bursty,\nintermittent, and heavy-tailed regimes, where its operational value for\nhigh-stakes decision making is of paramount interest.", "AI": {"tldr": "NetBurst reframes forecasting of highly bursty, intermittent network telemetry as an event prediction task (when bursts occur and how large they are) using quantile-based codebooks and dual autoregressors, yielding large MASE improvements and better-structured embeddings versus strong baselines.", "motivation": "Standard forecasting benchmarks favor smooth/seasonal series; production network telemetry is bursty, intermittent, and heavy-tailed (Mandelbrot regimes). Modern AI models underperform there, motivating an event-centric formulation tailored to bursts.", "method": "Introduce NetBurst: an event-centric forecasting framework that predicts burst timing and magnitude via quantile-based codebooks and two autoregressive components. Outputs are quantile-coded burst sizes and event times rather than dense-value forecasts, enabling preservation of burstiness and compact embeddings.", "result": "On large-scale production network telemetry, NetBurst reduces MASE by 13\u2013605\u00d7 on service-level series relative to strong baselines (e.g., Chronos), preserves burst statistics, and produces embeddings that cluster ~5\u00d7 more cleanly than Chronos.", "conclusion": "Leveraging Mandelbrot-style thinking for heavy-tailed, intermittent time series improves forecasting and representation quality in operational network telemetry; the event-centric quantile/codebook approach appears particularly effective in these regimes."}}

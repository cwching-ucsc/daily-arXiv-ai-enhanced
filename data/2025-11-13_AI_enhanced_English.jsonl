{"id": "2511.08998", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.08998", "abs": "https://arxiv.org/abs/2511.08998", "authors": ["Zilinghan Li", "Aditya Sinha", "Yijiang Li", "Kyle Chard", "Kibaek Kim", "Ravi Madduri"], "title": "Experiences Building Enterprise-Level Privacy-Preserving Federated Learning to Power AI for Science", "comment": null, "summary": "Federated learning (FL) is a promising approach to enabling collaborative model training without centralized data sharing, a crucial requirement in scientific domains where data privacy, ownership, and compliance constraints are critical. However, building user-friendly enterprise-level FL frameworks that are both scalable and privacy-preserving remains challenging, especially when bridging the gap between local prototyping and distributed deployment across heterogeneous client computing infrastructures. In this paper, based on our experiences building the Advanced Privacy-Preserving Federated Learning (APPFL) framework, we present our vision for an enterprise-grade, privacy-preserving FL framework designed to scale seamlessly across computing environments. We identify several key capabilities that such a framework must provide: (1) Scalable local simulation and prototyping to accelerate experimentation and algorithm design; (2) seamless transition from simulation to deployment; (3) distributed deployment across diverse, real-world infrastructures, from personal devices to cloud clusters and HPC systems; (4) multi-level abstractions that balance ease of use and research flexibility; and (5) comprehensive privacy and security through techniques such as differential privacy, secure aggregation, robust authentication, and confidential computing. We further discuss architectural designs to realize these goals. This framework aims to bridge the gap between research prototypes and enterprise-scale deployment, enabling scalable, reliable, and privacy-preserving AI for science.", "AI": {"tldr": "APPFL proposes an enterprise-grade federated learning framework that supports scalable local simulation, seamless transition to distributed deployment across heterogeneous infrastructures, multi-level abstractions for usability and research, and strong privacy/security controls (DP, secure aggregation, authentication, confidential computing).", "motivation": "Address the practical gap between FL research prototypes and real-world enterprise/scientific deployment where data privacy, ownership, regulatory compliance, and heterogeneous client infrastructures make centralized training infeasible. Enable reproducible prototyping and reliable, scalable deployment.", "method": "Design and engineering of the APPFL framework guided by five required capabilities: (1) fast, scalable local simulation and prototyping; (2) transparent transition from simulation to live deployment; (3) support for diverse client environments (personal devices, cloud, HPC); (4) multi-level APIs/abstractions balancing ease-of-use and research flexibility; (5) integrated privacy/security primitives (differential privacy, secure aggregation, robust auth, confidential computing). The paper discusses architectural designs to realize these goals.", "result": "A vision and architecture for an enterprise-grade, privacy-preserving FL framework built from the authors' experience developing APPFL. The abstract indicates design descriptions and proposed components, but does not report quantitative benchmarks in the abstract.", "conclusion": "APPFL aims to bridge research prototypes and enterprise deployments by providing scalable simulation tooling, seamless deployment paths, cross-infrastructure support, layered abstractions, and integrated privacy/security, thereby enabling scalable, reliable, privacy-preserving AI for scientific applications."}}
{"id": "2511.08851", "categories": ["cs.NI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.08851", "abs": "https://arxiv.org/abs/2511.08851", "authors": ["Po-Heng Chou", "Da-Chih Lin", "Hung-Yu Wei", "Walid Saad", "Yu Tsao"], "title": "Learning-based Radio Link Failure Prediction Based on Measurement Dataset in Railway Environments", "comment": "7 pages, 3 figures, 2 tables, and submitted to IEEE ICC 2026", "summary": "In this paper, a measurement-driven framework is proposed for early radio link failure (RLF) prediction in 5G non-standalone (NSA) railway environments. Using 10 Hz metro-train traces with serving and neighbor-cell indicators, we benchmark six models, namely CNN, LSTM, XGBoost, Anomaly Transformer, PatchTST, and TimesNet, under varied observation windows and prediction horizons. When the observation window is three seconds, TimesNet attains the highest F1 score with a three-second prediction horizon, while CNN provides a favorable accuracy-latency tradeoff with a two-second horizon, enabling proactive actions such as redundancy and adaptive handovers. The results indicate that deep temporal models can anticipate reliability degradations several seconds in advance using lightweight features available on commercial devices, offering a practical path to early-warning control in 5G-based railway systems.", "AI": {"tldr": "Benchmarking of six models on 10 Hz metro-train traces shows TimesNet yields the best F1 for 3s observation and 3s horizon; CNN gives a strong accuracy-latency tradeoff for 2s horizon, enabling proactive 5G railway RLF mitigation.", "motivation": "Provide an early-warning, measurement-driven framework to predict radio link failures (RLF) in 5G non-standalone (NSA) railway settings, enabling proactive reliability actions (redundancy, adaptive handovers) using lightweight, on-device features.", "method": "Use 10 Hz metro-train traces with serving and neighbor-cell indicators; benchmark six models (CNN, LSTM, XGBoost, Anomaly Transformer, PatchTST, TimesNet) across varied observation windows and prediction horizons; evaluate F1, accuracy, and latency tradeoffs to determine practical early-warning capabilities.", "result": "TimesNet achieved the highest F1 with a 3s observation window predicting 3s ahead. CNN provided a favorable accuracy-latency tradeoff at a 2s horizon, suitable for low-latency proactive control. Deep temporal models can predict reliability degradations several seconds in advance using lightweight commercial-device features.", "conclusion": "Measurement-driven temporal models can enable practical early-warning control for 5G-based railway systems; selecting a model depends on the required horizon and latency constraints, with TimesNet best for accuracy and CNN best for fast reactions."}}
{"id": "2511.09410", "categories": ["cs.DC", "cs.DS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.09410", "abs": "https://arxiv.org/abs/2511.09410", "authors": ["Yusuf Motiwala"], "title": "No Cords Attached: Coordination-Free Concurrent Lock-Free Queues", "comment": "10 pages, 2 figures, 3 tables. Lock-free concurrent queue with coordination-free memory reclamation", "summary": "The queue is conceptually one of the simplest data structures-a basic FIFO container. However, ensuring correctness in the presence of concurrency makes existing lock-free implementations significantly more complex than their original form. Coordination mechanisms introduced to prevent hazards such as ABA, use-after-free, and unsafe reclamation often dominate the design, overshadowing the queue itself. Many schemes compromise strict FIFO ordering, unbounded capacity, or lock-free progress to mask coordination overheads. Yet the true source of complexity lies in the pursuit of infinite protection against reclamation hazards--theoretically sound but impractical and costly. This pursuit not only drives unnecessary complexity but also creates a protection paradox where excessive protection reduces system resilience rather than improving it. While such costs may be tolerable in conventional workloads, the AI era has shifted the paradigm: training and inference pipelines involve hundreds to thousands of concurrent threads per node, and at this scale, protection and coordination overheads dominate, often far heavier than the basic queue operations themselves.\n  This paper introduces Cyclic Memory Protection (CMP), a coordination-free queue that preserves strict FIFO semantics, unbounded capacity, and lock-free progress while restoring simplicity. CMP reclaims the strict FIFO that other approaches sacrificed through bounded protection windows that provide practical reclamation guarantees. We prove strict FIFO and safety via linearizability and bounded reclamation analysis, and show experimentally that CMP outperforms state-of-the-art lock-free queues by up to 1.72-4x under high contention while maintaining scalability to hundreds of threads. Our work demonstrates that highly concurrent queues can return to their fundamental simplicity without weakening queue semantics.", "AI": {"tldr": "CMP (Cyclic Memory Protection) is a coordination-free lock-free queue that restores strict FIFO, unbounded capacity, and linearizability by using bounded protection windows for practical memory reclamation; it claims 1.72\u20134x speedups under high contention and scales to hundreds of threads.", "motivation": "Existing lock-free queues become complex due to aggressive, theoretically complete reclamation schemes (ABA prevention, use-after-free, safe reclamation). This complexity is exacerbated by modern AI workloads with hundreds-to-thousands of threads, where coordination/reclamation overheads dominate. The paper argues that infinite protection is impractical and proposes a practical bounded approach.", "method": "Introduce Cyclic Memory Protection: a coordination-free queue design that uses cyclic/bounded protection windows to enable practical reclamation while preserving strict FIFO semantics, unbounded capacity, and lock-free progress. Prove linearizability and provide bounded reclamation analysis.", "result": "Formal proofs of strict FIFO and safety (linearizability) plus bounded reclamation guarantees. Experimental results show CMP outperforms state-of-the-art lock-free queues by 1.72\u20134x under high contention and scales to hundreds of threads.", "conclusion": "CMP demonstrates that relaxing the goal of infinite protection to bounded, practical protection windows simplifies queue design without sacrificing semantics or scalability; it suggests revisiting coordination trade-offs in highly concurrent environments."}}
{"id": "2511.09087", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09087", "abs": "https://arxiv.org/abs/2511.09087", "authors": ["Vijay K Shah", "Cong Shen"], "title": "Tele-LLM-Hub: Building Context-Aware Multi-Agent LLM Systems for Telecom Networks", "comment": null, "summary": "This paper introduces Tele-LLM-Hub, a user friendly low-code solution for rapid prototyping and deployment of context aware multi-agent (MA) Large Language Model (LLM) systems tailored for 5G and beyond. As telecom wireless networks become increasingly complex, intelligent LLM applications must share a domainspecific understanding of network state. We propose TeleMCP, the Telecom Model Context Protocol, to enable structured and context-rich communication between agents in telecom environments. Tele-LLM-Hub actualizes TeleMCP through a low-code interface that supports agent creation, workflow composition, and interaction with software stacks such as srsRAN. Key components include a direct chat interface, a repository of pre-built systems, an Agent Maker leveraging finetuning with our RANSTRUCT framework, and an MA-Maker for composing MA workflows. The goal of Tele-LLM-Hub is to democratize the design of contextaware MA systems and accelerate innovation in next-generation wireless networks.", "AI": {"tldr": "Tele-LLM-Hub is a low-code platform that enables rapid prototyping and deployment of context-aware multi-agent LLM systems for telecom by defining TeleMCP (a telecom context protocol), offering agent creation (finetuning via RANSTRUCT), workflow composition, and integration with stacks like srsRAN.", "motivation": "Tele/5G networks are complex and require LLM-based agents to share domain-specific, structured network state to coordinate decisions; building such MA systems is currently specialist-heavy and slow to prototype.", "method": "Define TeleMCP for structured telecom agent communication; implement Tele-LLM-Hub with a low-code UI, direct chat, repository of systems, Agent Maker (finetuning via RANSTRUCT), and MA-Maker to compose multi-agent workflows; integrate with srsRAN for real-world interaction.", "result": "A software platform (Tele-LLM-Hub) that operationalizes TeleMCP and supports agent creation and MA workflow composition, purportedly lowering the barrier to design of context-aware MA systems for next-gen wireless networks.", "conclusion": "Tele-LLM-Hub democratizes context-aware multi-agent LLM system design in telecom, accelerating innovation in 5G and beyond by providing a standardized protocol, tooling, and integration path to network stacks."}}
{"id": "2511.09485", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09485", "abs": "https://arxiv.org/abs/2511.09485", "authors": ["Miroslav Popovic", "Marko Popovic", "Pavle Vasiljevic", "Miodrag Djukic"], "title": "Formal Verification of a Generic Algorithm for TDM Communication Over Inter Satellite Links", "comment": "4 pages, 1 figure, 3 tables", "summary": "The Python Testbed for Federated Learning Algorithms is a simple FL framework targeting edge systems, which provides the three generic algorithms: the centralized federated learning, the decentralized federated learning, and the universal TDM communication in the current time slot. The first two were formally verified in a previous paper using the CSP process algebra, and in this paper, we use the same approach to formally verify the third one, in two phases. In the first phase, we construct the CSP model as a faithful representation of the real Python code. In the second phase, the model checker PAT automatically proves correctness of the third generic algorithm by proving its deadlock freeness (safety property) and successful termination (liveness property).", "AI": {"tldr": "Authors model the universal TDM communication algorithm from a Python federated-learning testbed in CSP and use the PAT model checker to automatically prove its safety (deadlock freeness) and liveness (successful termination).", "motivation": "Provide formal guarantees for the third generic algorithm (universal TDM communication) in the Python FL testbed so the framework for edge systems is correct and reliable, extending previous formal verification of the first two algorithms.", "method": "Two-phase approach: (1) construct a CSP model intended to be a faithful representation of the real Python implementation; (2) use the PAT model checker to automatically verify properties (deadlock freeness and successful termination) on that CSP model.", "result": "PAT automatically proved correctness of the third algorithm by establishing the specified safety and liveness properties.", "conclusion": "The paper extends prior formal verification work on the testbed by adding a mechanically checked proof that the universal TDM communication algorithm is free from deadlock and always terminates (within the modeled assumptions), increasing the assurance of the FL framework for edge deployment."}}

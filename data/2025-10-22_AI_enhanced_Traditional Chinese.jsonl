{"id": "2510.17852", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17852", "abs": "https://arxiv.org/abs/2510.17852", "authors": ["Yuze Sun", "Wentao Luo", "Yanfei Xiang", "Jiancheng Pan", "Jiahao Li", "Quan Zhang", "Xiaomeng Huang"], "title": "Deploying Atmospheric and Oceanic AI Models on Chinese Hardware and Framework: Migration Strategies, Performance Optimization and Analysis", "comment": null, "summary": "With the growing role of artificial intelligence in climate and weather\nresearch, efficient model training and inference are in high demand. Current\nmodels like FourCastNet and AI-GOMS depend heavily on GPUs, limiting hardware\nindependence, especially for Chinese domestic hardware and frameworks. To\naddress this issue, we present a framework for migrating large-scale\natmospheric and oceanic models from PyTorch to MindSpore and optimizing for\nChinese chips, and evaluating their performance against GPUs. The framework\nfocuses on software-hardware adaptation, memory optimization, and parallelism.\nFurthermore, the model's performance is evaluated across multiple metrics,\nincluding training speed, inference speed, model accuracy, and energy\nefficiency, with comparisons against GPU-based implementations. Experimental\nresults demonstrate that the migration and optimization process preserves the\nmodels' original accuracy while significantly reducing system dependencies and\nimproving operational efficiency by leveraging Chinese chips as a viable\nalternative for scientific computing. This work provides valuable insights and\npractical guidance for leveraging Chinese domestic chips and frameworks in\natmospheric and oceanic AI model development, offering a pathway toward greater\ntechnological independence.", "AI": {"tldr": "\u63d0\u51fa\u5c07\u5927\u578b\u6c23\u8c61\u6d77\u6d0b AI \u6a21\u578b\u5f9e PyTorch \u9077\u79fb\u5230 MindSpore\uff0c\u4e26\u91dd\u5c0d\u4e2d\u570b\u570b\u7522\u6676\u7247\u9032\u884c\u8edf\u786c\u9ad4\u9069\u914d\u8207\u512a\u5316\uff1b\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u6642\uff0c\u63d0\u5347\u904b\u884c\u6548\u7387\u4e26\u964d\u4f4e\u5c0d GPU \u7684\u4f9d\u8cf4\u3002", "motivation": "\u73fe\u6709\u5148\u9032\u6c23\u8c61/\u6d77\u6d0b AI \u6a21\u578b\u9ad8\u5ea6\u4f9d\u8cf4 GPU \u8207 PyTorch\uff0c\u5c0e\u81f4\u5c0d\u570b\u7522\u786c\u9ad4\u8207\u751f\u614b\u7cfb\u7d71\u7684\u76f8\u5bb9\u6027\u5dee\u3001\u6280\u8853\u81ea\u4e3b\u6027\u53d7\u9650\u3002\u9700\u8981\u4e00\u5957\u6d41\u7a0b\u5c07\u6a21\u578b\u3001\u8a13\u7df4\u8207\u63a8\u7406\u79fb\u690d\u5230\u570b\u5167\u6846\u67b6\u8207\u6676\u7247\u4e0a\uff0c\u4e26\u8a55\u4f30\u6548\u80fd\u8207\u80fd\u8017\u3002", "method": "\u5efa\u7acb\u4e00\u500b\u9077\u79fb\u8207\u512a\u5316\u6846\u67b6\uff1a\u5c07\u6a21\u578b\u5f9e PyTorch \u8f49\u70ba MindSpore\uff1b\u91dd\u5c0d\u570b\u7522\u6676\u7247\u505a\u8edf\u786c\u9ad4\u9069\u914d\uff08\u904b\u7b97\u5716\u3001\u7b97\u5b50\u5be6\u73fe\uff09\u3001\u8a18\u61b6\u9ad4\u512a\u5316\uff08\u8a18\u61b6\u9ad4\u5fa9\u7528\u3001\u5206\u6bb5\u8f09\u5165\uff09\u3001\u4e26\u884c\u7b56\u7565\uff08\u6578\u64da/\u6a21\u578b\u4e26\u884c\uff09\uff1b\u4ee5\u8a13\u7df4\u901f\u5ea6\u3001\u63a8\u7406\u901f\u5ea6\u3001\u6a21\u578b\u6e96\u78ba\u5ea6\u8207\u80fd\u6548\u7b49\u6307\u6a19\u8207 GPU \u5be6\u73fe\u6bd4\u8f03\u3002", "result": "\u5be6\u9a57\u986f\u793a\uff0c\u5728\u4fdd\u7559\u539f\u6a21\u578b\u6e96\u78ba\u5ea6\u7684\u540c\u6642\uff0c\u900f\u904e\u91dd\u5c0d\u6027\u512a\u5316\u80fd\u5728\u570b\u7522\u6676\u7247\u4e0a\u9054\u5230\u53ef\u89c0\u7684\u904b\u884c\u6548\u7387\u8207\u80fd\u8017\u512a\u52e2\uff0c\u964d\u4f4e\u7cfb\u7d71\u76f8\u4f9d\u6027\uff0c\u5c55\u793a\u4e2d\u570b\u6676\u7247\u5728\u79d1\u5b78\u8a08\u7b97\u4e0a\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8a72\u5de5\u4f5c\u70ba\u5728\u5927\u6c23\u8207\u6d77\u6d0b AI \u9818\u57df\u63a1\u7528\u570b\u7522\u6676\u7247\u8207\u6846\u67b6\u63d0\u4f9b\u4e86\u5be6\u52d9\u6d41\u7a0b\u8207\u521d\u6b65\u8b49\u64da\uff0c\u4fc3\u9032\u6280\u8853\u81ea\u4e3b\u5316\uff1b\u5f8c\u7e8c\u4ecd\u9700\u66f4\u5ee3\u6cdb\u7684\u57fa\u6e96\u6e2c\u8a66\u3001\u958b\u6e90\u5fa9\u73fe\u8207\u786c\u9ad4\u591a\u6a23\u6027\u9a57\u8b49\u3002"}}
{"id": "2510.18300", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18300", "abs": "https://arxiv.org/abs/2510.18300", "authors": ["Ankur Lahiry", "Ayush Pokharel", "Banooqa Banday", "Seth Ockerman", "Amal Gueroudji", "Mohammad Zaeed", "Tanzima Z. Islam", "Line Pouchard"], "title": "A Distributed Framework for Causal Modeling of Performance Variability in GPU Traces", "comment": null, "summary": "Large-scale GPU traces play a critical role in identifying performance\nbottlenecks within heterogeneous High-Performance Computing (HPC)\narchitectures. However, the sheer volume and complexity of a single trace of\ndata make performance analysis both computationally expensive and\ntime-consuming. To address this challenge, we present an end-to-end parallel\nperformance analysis framework designed to handle multiple large-scale GPU\ntraces efficiently. Our proposed framework partitions and processes trace data\nconcurrently and employs causal graph methods and parallel coordinating chart\nto expose performance variability and dependencies across execution flows.\nExperimental results demonstrate a 67% improvement in terms of scalability,\nhighlighting the effectiveness of our pipeline for analyzing multiple traces\nindependently.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u500b\u53ef\u4e26\u884c\u8655\u7406\u591a\u4efd\u5927\u578b GPU \u8ffd\u8e64\uff08trace\uff09\u7684\u7aef\u5230\u7aef\u5206\u6790\u6846\u67b6\uff0c\u900f\u904e\u8cc7\u6599\u5207\u5206\u8207\u4e26\u884c\u8655\u7406\u3001\u56e0\u679c\u5716\uff08causal graph\uff09\u65b9\u6cd5\u8207\u5e73\u884c\u5354\u8abf\u5716\uff08parallel coordinating chart\uff09\u4f86\u63ed\u793a\u57f7\u884c\u6d41\u7a0b\u9593\u7684\u6027\u80fd\u8b8a\u7570\u8207\u76f8\u4f9d\u6027\uff0c\u5be6\u9a57\u986f\u793a\u53ef\u9054\u7d04 67% \u7684\u53ef\u64f4\u5c55\u6027\u63d0\u5347\u3002", "motivation": "\u55ae\u7b46\u6216\u591a\u7b46\u5927\u578b GPU \u8ffd\u8e64\u8cc7\u6599\u91cf\u9f90\u5927\u4e14\u7d50\u69cb\u8907\u96dc\uff0c\u50b3\u7d71\u9010\u7b46\u6216\u55ae\u6a5f\u5206\u6790\u5728\u6642\u6548\u6027\u8207\u8a08\u7b97\u8cc7\u6e90\u4e0a\u96e3\u4ee5\u627f\u53d7\uff1b\u5c24\u5176\u5728\u7570\u8cea HPC \u67b6\u69cb\u4e0b\uff0c\u8b58\u5225\u8de8\u6d41\u7a0b\u6027\u80fd\u74f6\u9838\u8207\u76f8\u4f9d\u6027\u9700\u8981\u53ef\u64f4\u5c55\u4e14\u80fd\u8655\u7406\u591a trace \u7684\u65b9\u6cd5\u3002", "method": "\u8a2d\u8a08\u4e00\u500b\u7aef\u5230\u7aef\u7ba1\u7dda\uff1a\u5148\u5c07 trace \u8cc7\u6599\u5206\u5272\u70ba\u53ef\u4e26\u884c\u8655\u7406\u7684\u5340\u6bb5\uff08partition\uff09\uff0c\u5c0d\u5404\u5340\u6bb5\u63a1\u7528\u4e26\u884c\u8655\u7406\u7b56\u7565\uff1b\u5229\u7528\u56e0\u679c\u5716\u65b9\u6cd5\u63a8\u65b7\u4e8b\u4ef6\u9593\u7684\u4f9d\u8cf4\u95dc\u4fc2\uff0c\u4e26\u4ee5\u6240\u8b02\u7684\u5e73\u884c\u5354\u8abf\u5716\u4f86\u8868\u9054\u4e0d\u540c\u57f7\u884c\u6d41\u4e4b\u9593\u7684\u6642\u9593\u5c0d\u61c9\u8207\u8b8a\u7570\uff1b\u6574\u9ad4\u4ee5\u591a\u5de5\u4f5c\u4e26\u884c\u57f7\u884c\u4f86\u52a0\u901f\u591a\u7b46 trace \u7684\u5206\u6790\u3002", "result": "\u5728\u5be6\u9a57\u8a55\u4f30\u4e2d\uff0c\u8a72\u6846\u67b6\u76f8\u8f03\u65bc\u57fa\u7dda\u65b9\u6cd5\u5c55\u73fe\u4e86\u7d04 67% \u7684\u53ef\u64f4\u5c55\u6027\u6539\u5584\uff08scalability improvement\uff09\uff0c\u8868\u793a\u5728\u540c\u7b49\u8cc7\u6e90\u4e0b\u80fd\u66f4\u6709\u6548\u5730\u540c\u6642\u5206\u6790\u591a\u4efd\u5927\u578b trace\uff0c\u4e14\u80fd\u63ed\u793a\u51fa\u8de8\u6d41\u7a0b\u7684\u6027\u80fd\u8b8a\u7570\u8207\u76f8\u4f9d\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e4b\u53ef\u4e26\u884c\u591a trace \u5206\u6790\u7ba1\u7dda\u5728\u64f4\u5c55\u6027\u8207\u63ed\u9732\u6027\u80fd\u76f8\u4f9d\u6027\u65b9\u9762\u5177\u9ad4\u6210\u6548\uff0c\u9069\u5408\u7528\u65bc\u5927\u578b\u3001\u7570\u8cea HPC \u74b0\u5883\u7684 GPU \u8ffd\u8e64\u5206\u6790\uff1b\u4ecd\u9700\u66f4\u591a\u7d30\u7bc0\uff08\u5982 I/O \u6216\u8a18\u61b6\u9ad4\u74f6\u9838\u3001\u5177\u9ad4\u52a0\u901f\u57fa\u6e96\u3001\u9069\u7528\u8cc7\u6599\u96c6\u7bc4\u570d\uff09\u4ee5\u5229\u5168\u9762\u8a55\u4f30\u8207\u5be6\u4f5c\u8907\u73fe\u3002"}}
{"id": "2510.18058", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18058", "abs": "https://arxiv.org/abs/2510.18058", "authors": ["Hongbo Lu", "Junsung Hwang", "Bernard Tenreiro", "Nabila Jaman Tripti", "Darren Hamilton", "Yuefan Deng"], "title": "A New Broadcast Model for Several Network Topologies", "comment": "19 pages, 11 figures", "summary": "We present Broadcast by Balanced Saturation (BBS), a general broadcast\nalgorithm designed to optimize communication efficiency across diverse network\ntopologies. BBS maximizes node utilization, addressing challenges in broadcast\noperations such as topology constraints, bandwidth limitations, and\nsynchronization overhead, particularly in large-scale systems like\nsupercomputers. The algorithm ensures sustained activity with nodes throughout\nthe broadcast, thereby enhancing data propagation and significantly reducing\nlatency. Through a precise communication cycle, BBS provides a repeatable,\nstreamlined, stepwise broadcasting framework. Simulation results across various\ntopologies demonstrate that the BBS algorithm consistently outperforms common\ngeneral broadcast algorithms, often by a substantial margin. These findings\nsuggest that BBS is a versatile and robust framework with the potential to\nredefine broadcast strategies across network topologies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u7a2e\u540d\u70ba BBS\uff08Broadcast by Balanced Saturation\uff09\u7684\u5ee3\u64ad\u6f14\u7b97\u6cd5\uff0c\u900f\u904e\u5e73\u8861\u7bc0\u9ede\u5229\u7528\u7387\u8207\u7cbe\u78ba\u901a\u8a0a\u9031\u671f\u4f86\u63d0\u5347\u4e0d\u540c\u7db2\u8def\u62d3\u6a38\u4e0b\u7684\u5ee3\u64ad\u6548\u7387\uff0c\u6a21\u64ec\u7d50\u679c\u986f\u793a\u666e\u904d\u512a\u65bc\u5e38\u898b\u5ee3\u64ad\u6f14\u7b97\u6cd5\u3002", "motivation": "\u89e3\u6c7a\u5927\u578b\u7cfb\u7d71\uff08\u5982\u8d85\u7d1a\u96fb\u8166\uff09\u4e2d\u5ee3\u64ad\u9762\u81e8\u7684\u62d3\u6a38\u9650\u5236\u3001\u983b\u5bec\u74f6\u9838\u8207\u540c\u6b65\u958b\u92b7\uff0c\u4e26\u63d0\u5347\u7bc0\u9ede\u5728\u6574\u500b\u5ee3\u64ad\u904e\u7a0b\u4e2d\u7684\u6d3b\u8e8d\u5ea6\u4ee5\u7e2e\u77ed\u5ef6\u9072\u3002", "method": "\u8a2d\u8a08\u4e00\u500b\u5177\u91cd\u8907\u6027\u4e14\u6b65\u9a5f\u5316\u7684\u901a\u8a0a\u9031\u671f\uff0c\u4f7f\u7bc0\u9ede\u6301\u7e8c\u53c3\u8207\u8cc7\u6599\u8f49\u64ad\u4ee5\u9054\u5230\u98fd\u548c\u4e14\u5e73\u8861\u7684\u8cc7\u6e90\u4f7f\u7528\uff08balanced saturation\uff09\uff1b\u5728\u591a\u7a2e\u62d3\u6a38\u4e0a\u4ee5\u6a21\u64ec\u5be6\u9a57\u9a57\u8b49\u6548\u80fd\u3002", "result": "\u6a21\u64ec\u986f\u793a BBS \u5728\u591a\u7a2e\u7db2\u8def\u62d3\u6a38\u4e0a\uff0c\u901a\u5e38\u4ee5\u986f\u8457\u5e45\u5ea6\u512a\u65bc\u4e00\u822c\u7684\u901a\u7528\u5ee3\u64ad\u6f14\u7b97\u6cd5\uff0c\u5ef6\u9072\u964d\u4f4e\u4e14\u7bc0\u9ede\u5229\u7528\u7387\u63d0\u9ad8\u3002", "conclusion": "BBS \u662f\u4e00\u5957\u5177\u901a\u7528\u6027\u8207\u97cc\u6027\u7684\u5ee3\u64ad\u6846\u67b6\uff0c\u6709\u6f5b\u529b\u6539\u9032\u4e0d\u540c\u62d3\u6a38\u4e0b\u7684\u5ee3\u64ad\u7b56\u7565\uff0c\u4f7f\u5927\u578b\u7cfb\u7d71\u7684\u8cc7\u6599\u50b3\u64ad\u66f4\u9ad8\u6548\u3002"}}
{"id": "2510.18417", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18417", "abs": "https://arxiv.org/abs/2510.18417", "authors": ["Rahul Soundrarajan", "Claudio Fiandrino", "Michele Polese", "Salvatore D'Oro", "Leonardo Bonati", "Tommaso Melodia"], "title": "On AI Verification in Open RAN", "comment": null, "summary": "Open RAN introduces a flexible, cloud-based architecture for the Radio Access\nNetwork (RAN), enabling Artificial Intelligence (AI)/Machine Learning\n(ML)-driven automation across heterogeneous, multi-vendor deployments. While\nEXplainable Artificial Intelligence (XAI) helps mitigate the opacity of AI\nmodels, explainability alone does not guarantee reliable network operations. In\nthis article, we propose a lightweight verification approach based on\ninterpretable models to validate the behavior of Deep Reinforcement Learning\n(DRL) agents for RAN slicing and scheduling in Open RAN. Specifically, we use\nDecision Tree (DT)-based verifiers to perform near-real-time consistency checks\nat runtime, which would be otherwise unfeasible with computationally expensive\nstate-of-the-art verifiers. We analyze the landscape of XAI and AI\nverification, propose a scalable architectural integration, and demonstrate\nfeasibility with a DT-based slice-verifier. We also outline future challenges\nto ensure trustworthy AI adoption in Open RAN.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u6c7a\u7b56\u6a39\u70ba\u57fa\u790e\u7684\u8f15\u91cf\u9a57\u8b49\u5668\uff0c\u5728 Open RAN \u4e2d\u5c0d\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2\u7684\u5207\u7247\u8207\u6392\u7a0b\u884c\u70ba\u9032\u884c\u8fd1\u5be6\u6642\u4e00\u81f4\u6027\u6aa2\u67e5\uff0c\u85c9\u6b64\u88dc\u5f37 XAI \u89e3\u91cb\u6027\u4f46\u4e0d\u8db3\u4ee5\u4fdd\u8b49\u7db2\u8def\u53ef\u9760\u6027\u7684\u7f3a\u53e3\u3002", "motivation": "Open RAN \u5f15\u5165\u591a\u4f9b\u61c9\u5546\u3001\u96f2\u5316\u8207 AI/ML \u81ea\u52d5\u5316\uff0c\u4f7f\u5f97 DRL \u7b49\u9ed1\u7bb1\u6a21\u578b\u5728\u95dc\u9375\u7684 RAN \u5207\u7247\u8207\u6392\u7a0b\u6c7a\u7b56\u4e2d\u88ab\u63a1\u7528\uff1b\u7136\u800c\u50c5\u6709\u53ef\u89e3\u91cb\u6027\uff08XAI\uff09\u4ecd\u4e0d\u8db3\u4ee5\u78ba\u4fdd\u904b\u4f5c\u6b63\u78ba\u8207\u5b89\u5168\uff0c\u9700\u6709\u53ef\u57f7\u884c\u7684\u884c\u70ba\u9a57\u8b49\u6a5f\u5236\u3002", "method": "\u63d0\u51fa\u4ee5\u53ef\u89e3\u91cb\u6a21\u578b\uff08Decision Tree\uff09\u4f5c\u70ba\u8f15\u91cf\u9a57\u8b49\u5668\uff0c\u5728\u904b\u884c\u6642\u5c0d DRL agent \u7684\u6c7a\u7b56\u57f7\u884c\u8fd1\u5373\u6642\u7684\u4e00\u81f4\u6027\u6aa2\u67e5\uff1b\u5206\u6790 XAI \u8207 AI \u9a57\u8b49\u7684\u73fe\u6cc1\uff0c\u8a2d\u8a08\u53ef\u64f4\u5c55\u7684\u67b6\u69cb\u6574\u5408\u65b9\u6848\uff0c\u4e26\u4ee5 DT-based slice-verifier \u5be6\u4f5c\u9a57\u8b49\u53ef\u884c\u6027\u3002", "result": "\u5c55\u793a DT \u9a57\u8b49\u5668\u80fd\u5728\u8fd1\u5be6\u6642\u57f7\u884c\u4e00\u81f4\u6027\u6aa2\u67e5\uff0c\u8f03\u5e02\u9762\u4e0a\u8a08\u7b97\u6602\u8cb4\u7684\u9a57\u8b49\u5668\u66f4\u9069\u5408\u904b\u884c\u6642\u4f7f\u7528\uff1b\u9a57\u8b49\u5668\u8207\u7cfb\u7d71\u67b6\u69cb\u5c55\u73fe\u51fa\u53ef\u64f4\u5145\u6027\u8207\u5be6\u52d9\u53ef\u884c\u6027\u3002", "conclusion": "\u4ee5\u53ef\u89e3\u91cb\u7684\u8f15\u91cf\u9a57\u8b49\u5668\u88dc\u5f37 XAI\uff0c\u80fd\u63d0\u9ad8 Open RAN \u4e2d DRL \u6c7a\u7b56\u7684\u53ef\u9760\u5ea6\uff1b\u4f46\u9700\u9762\u5c0d\u6a21\u578b\u8868\u9054\u529b\u3001\u9a57\u8b49\u6e96\u78ba\u5ea6\u3001\u653b\u64ca\u9632\u8b77\u8207\u6574\u5408\u6a19\u6e96\u5316\u7b49\u672a\u4f86\u6311\u6230\u3002"}}

{"id": "2512.00023", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00023", "abs": "https://arxiv.org/abs/2512.00023", "authors": ["Hetvi Shastri", "Akanksha Atrey", "Andre Beck", "Nirupama Ravi"], "title": "Trust or Bust: A Survey of Threats in Decentralized Wireless Networks", "comment": null, "summary": "The recent emergence of decentralized wireless networks empowers individual entities to own, operate, and offer subscriptionless connectivity services in exchange for monetary compensation. While traditional connectivity providers have built trust over decades through widespread adoption, established practices, and regulation, entities in a decentralized wireless network, lacking this foundation, may be incentivized to exploit the service for their own advantage. For example, a dishonest hotspot operator can intentionally violate the agreed upon connection terms in an attempt to increase their profits. In this paper, we examine and develop a taxonomy of adversarial behavior patterns in decentralized wireless networks. Our case study finds that provider-driven attacks can potentially more than triple provider earnings. We conclude the paper with a discussion on the critical need to develop novel techniques to detect and mitigate adversarial behavior in decentralized wireless networks."}
{"id": "2512.00025", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00025", "abs": "https://arxiv.org/abs/2512.00025", "authors": ["Yun Ji", "Zeyu Chen", "Xiaoxiong Zhong", "Yanan Ma", "Sheng Zhang", "Yuguang Fang"], "title": "Multi-Server FL with Overlapping Clients: A Latency-Aware Relay Framework", "comment": null, "summary": "Multi-server Federated Learning (FL) has emerged as a promising solution to mitigate communication bottlenecks of single-server FL. In a typical multi-server FL architecture, the regions covered by different edge servers (ESs) may overlap. Under this architecture, clients located in the overlapping areas can access edge models from multiple ESs. Building on this observation, we propose a cloud-free multi-server FL framework that leverages Overlapping Clients (OCs) as relays for inter-server model exchange while uploading the local updated model to ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs without introducing new communication links. We derive a new convergence upper bound for non-convex objectives under non-IID data and an arbitrary number of cells, which explicitly quantifies the impact of inter-server propagation depth on convergence error. Guided by this theoretical result, we formulate an optimization problem that aims to maximize dissemination range of each ES model among all ESs within a limited latency. To solve this problem, we develop a conflict-graph-based local search algorithm optimizing the routing strategy and scheduling the transmission times of individual ESs to its neighboring ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs, achieving the widest possible transmission coverage for each model without introducing new communication links. Extensive experimental results show remarkable performance gains of our scheme compared to existing methods."}
{"id": "2512.00029", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00029", "abs": "https://arxiv.org/abs/2512.00029", "authors": ["Andreas Kouloumpris", "Georgios L. Stavrinides", "Maria K. Michael", "Theocharis Theocharides"], "title": "An optimization framework for task allocation in the edge/hub/cloud paradigm", "comment": "This version of the manuscript has been accepted for publication in Future Generation Computer Systems after peer review (Author Accepted Manuscript). It is not the final published version (Version of Record) and does not reflect any post-acceptance improvements. The Version of Record is available online at https://doi.org/10.1016/j.future.2024.02.005", "summary": "With the advent of the Internet of Things (IoT), novel critical applications have emerged that leverage the edge/hub/cloud paradigm, which diverges from the conventional edge computing perspective. A growing number of such applications require a streamlined architecture for their effective execution, often comprising a single edge device with sensing capabilities, a single hub device (e.g., a laptop or smartphone) for managing and assisting the edge device, and a more computationally capable cloud server. Typical examples include the utilization of an unmanned aerial vehicle (UAV) for critical infrastructure inspection or a wearable biomedical device (e.g., a smartwatch) for remote patient monitoring. Task allocation in this streamlined architecture is particularly challenging, due to the computational, communication, and energy limitations of the devices at the network edge. Consequently, there is a need for a comprehensive framework that can address the specific task allocation problem optimally and efficiently. To this end, we propose a complete, binary integer linear programming (BILP) based formulation for an application-driven design-time approach, capable of providing an optimal task allocation in the targeted edge/hub/cloud environment. The proposed method minimizes the desired objective, either the overall latency or overall energy consumption, while considering several crucial parameters and constraints often overlooked in related literature. We evaluate our framework using a real-world use-case scenario, as well as appropriate synthetic benchmarks. Our extensive experimentation reveals that the proposed approach yields optimal and scalable results, enabling efficient design space exploration for different applications and computational devices."}
{"id": "2512.00036", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00036", "abs": "https://arxiv.org/abs/2512.00036", "authors": ["Parth Ashokbhai Shiroya", "Amod Ashtekar", "Swarnagowri Shashidhar", "Mohammed E. Eltayeb"], "title": "Refined Bayesian Optimization for Efficient Beam Alignment in Intelligent Indoor Wireless Environments", "comment": null, "summary": "Future intelligent indoor wireless environments re- quire fast and reliable beam alignment to sustain high-throughput links under mobility and blockage. Exhaustive beam training achieves optimal performance but is prohibitively costly. In indoor settings, dense scatterers and transceiver hardware imperfections introduce multipath and sidelobe leakage, producing measurable power across multiple angles and reducing the effectiveness of outdoor-oriented alignment algorithms. This paper presents a Refined Bayesian Optimization (R-BO) framework that exploits the inherent structure of mmWave transceiver patterns, where received power gradually increases as the transmit and receive beams converge toward the optimum. R-BO integrates a Gaussian Process (GP) surrogate with a Matern kernel and an Expected Improvement (EI) acquisition function, followed by a localized refinement around the predicted optimum. The GP hyperparam- eters are re-optimized online to adapt to irregular variations in the measured angular power field caused by reflections and sidelobe leakage. Experiments across 43 receiver positions in an indoor laboratory demonstrate 97.7% beam-alignment accuracy within 10 degrees, less than 0.3 dB average loss, and an 88% reduction in probing overhead compared to exhaustive search. These results establish R-BO as an efficient and adaptive beam-alignment solution for real-time intelligent indoor wireless environments."}
{"id": "2512.00233", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00233", "abs": "https://arxiv.org/abs/2512.00233", "authors": ["Davide Rucci", "Sebastian Parfeniuc", "Matteo Mordacchini", "Emanuele Carlini", "Alfredo Cuzzocrea", "Patrizio Dazzi"], "title": "A Parallel and Distributed Rust Library for Core Decomposition on Large Graphs", "comment": null, "summary": "In this paper, we investigate the parallelization of $k$-core decomposition, a method used in graph analysis to identify cohesive substructures and assess node centrality. Although efficient sequential algorithms exist for this task, the scale of modern networks requires faster, multicore-ready approaches. To this end, we adapt a distributed $k$-core algorithm originally proposed by Montresor et al. to shared-memory systems and implement it in Rust, leveraging the language's strengths in concurrency and memory safety. We developed three progressively optimized versions: SequentialK as a baseline, ParallelK introducing multi-threaded message passing, and FastK further reducing synchronization overhead. Extensive experiments on real-world datasets, including road networks, web graphs, and social networks, show that FastK consistently outperforms both SequentialK and ParallelK, as well as a reference Python implementation available in the NetworkX library. Results indicate up to an 11x speedup on 16 threads and execution times up to two orders of magnitude faster than the Python implementation."}
{"id": "2512.00039", "categories": ["cs.NI", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00039", "abs": "https://arxiv.org/abs/2512.00039", "authors": ["Tasnim Ahmed", "Siana Rizwan", "Naveed Ejaz", "Salimur Choudhury"], "title": "LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation", "comment": null, "summary": "Building on advancements in Large Language Models (LLMs), we can tackle complex analytical and mathematical reasoning tasks requiring nuanced contextual understanding. A prime example of such complex tasks is modelling resource allocation optimization in networks, which extends beyond translating natural language inputs into mathematical equations or Linear Programming (LP), Integer Linear Programming (ILP), and Mixed-Integer Linear Programming (MILP) models. However, existing benchmarks and datasets cannot address the complexities of such problems with dynamic environments, interdependent variables, and heterogeneous constraints. To address this gap, we introduce NL4RA, a curated dataset comprising 50 resource allocation optimization problems formulated as LP, ILP, and MILP. We then evaluate the performance of well-known open-source LLMs with varying parameter counts. To enhance existing LLM based methods, we introduce LM4Opt RA, a multi candidate framework that applies diverse prompting strategies such as direct, few shot, and chain of thought, combined with a structured ranking mechanism to improve accuracy. We identified discrepancies between human judgments and automated scoring such as ROUGE, BLEU, or BERT scores. However, human evaluation is time-consuming and requires specialized expertise, making it impractical for a fully automated end-to-end framework. To quantify the difference between LLM-generated responses and ground truth, we introduce LLM-Assisted Mathematical Evaluation (LAME), an automated metric designed for mathematical formulations. Using LM4Opt-RA, Llama-3.1-70B achieved a LAME score of 0.8007, outperforming other models by a significant margin, followed closely by Llama-3.1-8B. While baseline LLMs demonstrate considerable promise, they still lag behind human expertise; our proposed method surpasses these baselines regarding LAME and other metrics."}
{"id": "2512.00398", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00398", "abs": "https://arxiv.org/abs/2512.00398", "authors": ["Bingzheng Xia", "Zujie Ren", "Kuang Ma", "Xiaoqian Li", "Wenda Li", "Shuibing He"], "title": "Heimdall++: Optimizing GPU Utilization and Pipeline Parallelism for Efficient Single-Pulse Detection", "comment": null, "summary": "With the increasing time and frequency resolution of modern radio telescopes and the exponential growth in observational data volumes, real-time single-pulse detection has become a critical requirement for time-domain radio astronomy. Heimdall, as a representative GPU-accelerated single-pulse search tool, offers substantial performance advantages over CPU-based approaches. However, its sequential execution model and resource contention in intermediate processing stages limit GPU utilization, leading to suboptimal throughput and increased computational latency. To address these limitations, we present Heimdall++, an optimized successor to Heimdall that incorporates fine-grained GPU parallelization, enhanced memory management, and a multi-threaded framework to decouple CPU-bound and GPU-bound processing stages. This design mitigates the GPU stall problem and improves end-to-end efficiency. We evaluated Heimdall++ on a system equipped with NVIDIA RTX 3080 Ti GPUs using both a single large-scale observational file and multiple files. Experimental results demonstrate that Heimdall++ achieves up to 2.66x speedup in single-file processing and 2.05x speedup in multi-file batch processing, while maintaining full consistency with the original Heimdall's search results."}
{"id": "2512.00040", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00040", "abs": "https://arxiv.org/abs/2512.00040", "authors": ["Sagar Sudhakara", "Pankaj Rajak"], "title": "Constrained Network Slice Assignment via Large Language Models", "comment": "Accepted at NeurIPS 2025 Workshop on AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG), San Diego, CA", "summary": "Modern networks support network slicing, which partitions physical infrastructure into virtual slices tailored to different service requirements (for example, high bandwidth or low latency). Optimally allocating users to slices is a constrained optimization problem that traditionally requires complex algorithms. In this paper, we explore the use of Large Language Models (LLMs) to tackle radio resource allocation for network slicing. We focus on two approaches: (1) using an LLM in a zero-shot setting to directly assign user service requests to slices, and (2) formulating an integer programming model where the LLM provides semantic insight by estimating similarity between requests. Our experiments show that an LLM, even with zero-shot prompting, can produce a reasonable first draft of slice assignments, although it may violate some capacity or latency constraints. We then incorporate the LLM's understanding of service requirements into an optimization solver to generate an improved allocation. The results demonstrate that LLM-guided grouping of requests, based on minimal textual input, achieves performance comparable to traditional methods that use detailed numerical data, in terms of resource utilization and slice isolation. While the LLM alone does not perfectly satisfy all constraints, it significantly reduces the search space and, when combined with exact solvers, provides a promising approach for efficient 5G network slicing resource allocation."}
{"id": "2512.00595", "categories": ["cs.DC", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.00595", "abs": "https://arxiv.org/abs/2512.00595", "authors": ["Bala Siva Sai Akhil Malepati"], "title": "IslandRun: Privacy-Aware Multi-Objective Orchestration for Distributed AI Inference", "comment": "15 pages, 3 figures, 2 tables", "summary": "Modern AI inference faces an irreducible tension: no single computational resource simultaneously maximizes performance, preserves privacy, minimizes cost, and maintains trust. Existing orchestration frameworks optimize single dimensions (Kubernetes prioritizes latency, federated learning preserves privacy, edge computing reduces network distance), creating solutions that struggle under real-world heterogeneity. We present IslandRun, a multi-objective orchestration system that treats computational resources as autonomous \"islands\" spanning personal devices, private edge servers, and public cloud. Our key insights: (1) request-level heterogeneity demands policy-constrained multi-objective optimization, (2) data locality enables routing compute to data rather than data to compute, and (3) typed placeholder sanitization preserves context semantics across trust boundaries. IslandRun introduces agent-based routing, tiered island groups with differential trust, and reversible anonymization. This establishes a new paradigm for privacy-aware, decentralized inference orchestration across heterogeneous personal computing ecosystems."}
{"id": "2512.00161", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00161", "abs": "https://arxiv.org/abs/2512.00161", "authors": ["Ram Ramanathan", "Dmitrii Dugaev", "Liang Tan", "Warren Ramanathan"], "title": "Mesh Augmentation of LoRaWAN-based IoT Networks", "comment": null, "summary": "LoRaWAN is a leading standard and technology for low-power, long-range Internet-of-Things (IoT) communications. However, its single-hop architecture results in limited effective range and excessive power consumption for end devices, especially when deployed in large, remote and RF-challenged environments. Existing solutions are either incompatible with LoRaWAN, or limit relaying to a single hop. We present LIMA, a protocol for augmenting an existing or new LoRaWAN deployment with a mesh network of LIMA Routers. LIMA increases the effective coverage range well beyond the maximum LoRa range via multi-hopping, and significantly reduces the energy consumed by end-devices. LIMA requires no changes to the end-device, the servers or the LoRaWAN standard. LIMA builds routes using reverse path forwarding, tunnels LoRaWAN messages over LIMA, provides transparent extension of the existing Adaptive Data Rate (ADR), and suppresses duplicate forwarding if the device is directly reachable from the Gateway. Simulations using Network Simulator 3 (ns-3) show that LIMA increases the delivery rate, scalability, ED energy consumption by up to 5x, 8x and 12.6x respectively, and reduces latency by up to 2.3x. Table-top and outdoor testing with a prototype constructed using a commercial gateway as a starting point confirm that LIMA can be successfully deployed within an existing LoRaWAN system, and can provide range and energy gains transparently."}
{"id": "2512.00623", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00623", "abs": "https://arxiv.org/abs/2512.00623", "authors": ["Basilis Mamalis", "Marios Perlitis"], "title": "Steady and Energy-Efficient Multi-Hop Clustering for Flying Ad-Hoc Networks (FANETs)", "comment": "7 pages, 5 figures, Accepted for publication in International Journal of Computer Applications (IJCA) - December 2025 Edition", "summary": "Flying Ad-hoc Networks (FANETs), formed by Unmanned Aerial Vehicles (UAVs), represent an emerging and promising communication paradigm. These networks face unique challenges due to UAVs high mobility, limited energy resources, and dynamic topology. In this work, we propose a novel multi-hop clustering algorithm aimed at creating stable, energy-efficient clusters in FANET environments. The proposed solution enhances cluster longevity and communication efficiency through mobility-aware clustering, energy-centric cluster head (CH) selection, and a ground station(GS)-assisted cluster maintenance management mechanism. First, steady multi-hop clusters are constructed, having CHs with not only high stability and high energy but also with steady and high-energy neighboring areas, and then a proper GS-assisted cluster maintenance mechanism is applied. Experimental results, based on extended simulations, demonstrate that our approach outperforms existing schemes significantly, in terms of cluster stability, communication overhead, and security resilience."}
{"id": "2512.00211", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00211", "abs": "https://arxiv.org/abs/2512.00211", "authors": ["Gabriele Formis", "Amanda Ericson", "Stefan Forsstrom", "Kyi Thar", "Gianluca Cena", "Stefano Scanzio"], "title": "On the Prediction of Wi-Fi Performance through Deep Learning", "comment": "preprint accepted, 4 pages, 2025", "summary": "Ensuring reliable and predictable communications is one of the main goals in modern industrial systems that rely on Wi-Fi networks, especially in scenarios where continuity of operation and low latency are required. In these contexts, the ability to predict changes in wireless channel quality can enable adaptive strategies and significantly improve system robustness. This contribution focuses on the prediction of the Frame Delivery Ratio (FDR), a key metric that represents the percentage of successful transmissions, starting from time sequences of binary outcomes (success/failure) collected in a real scenario. The analysis focuses on two models of deep learning: a Convolutional Neural Network (CNN) and a Long Short-Term Memory network (LSTM), both selected for their ability to predict the outcome of time sequences. Models are compared in terms of prediction accuracy and computational complexity, with the aim of evaluating their applicability to systems with limited resources. Preliminary results show that both models are able to predict the evolution of the FDR with good accuracy, even from minimal information (a single binary sequence). In particular, CNN shows a significantly lower inference latency, with a marginal loss in accuracy compared to LSTM."}
{"id": "2512.00705", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00705", "abs": "https://arxiv.org/abs/2512.00705", "authors": ["Seongyeon Park", "Jaeyong Song", "Changmin Shin", "Sukjin Kim", "Junguk Hong", "Jinho Lee"], "title": "FlexiWalker: Extensible GPU Framework for Efficient Dynamic Random Walks with Runtime Adaptation", "comment": "To appear at EuroSys 2026", "summary": "Dynamic random walks are fundamental to various graph analysis applications, offering advantages by adapting to evolving graph properties. Their runtime-dependent transition probabilities break down the pre-computation strategy that underpins most existing CPU and GPU static random walk optimizations. This leaves practitioners suffering from suboptimal frameworks and having to write hand-tuned kernels that do not adapt to workload diversity. To handle this issue, we present FlexiWalker, the first GPU framework that delivers efficient, workload-generic support for dynamic random walks. Our design-space study shows that rejection sampling and reservoir sampling are more suitable than other sampling techniques under massive parallelism. Thus, we devise (i) new high-performance kernels for them that eliminate global reductions, redundant memory accesses, and random-number generation. Given the necessity of choosing the best-fitting sampling strategy at runtime, we adopt (ii) a lightweight first-order cost model that selects the faster kernel per node at runtime. To enhance usability, we introduce (iii) a compile-time component that automatically specializes user-supplied walk logic into optimized building blocks. On various dynamic random walk workloads with real-world graphs, FlexiWalker outperforms the best published CPU/GPU baselines by geometric means of 73.44x and 5.91x, respectively, while successfully executing workloads that prior systems cannot support. We open-source FlexiWalker in https://github.com/AIS-SNU/FlexiWalker."}
{"id": "2512.00221", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00221", "abs": "https://arxiv.org/abs/2512.00221", "authors": ["Stefano Scanzio", "Pietro Chiavassa", "Gianluca Cena"], "title": "Analysis of the operation of a TSN switch and other devices using executable QR codes", "comment": "preprint accepted, 2 pages, 2025", "summary": "Executable QR codes, also known as sQRy, are a technology aimed at inserting executable programs in a QR code. Through a concrete example, in this paper, we demonstrate their usage in the context of industrial networks in order to assess the operation of a TSN switch by analyzing its status LEDs even in the absence of an internet connection. The entire generation chain that is used to create the sQRy, as well as the corresponding execution chain that, starting from the sQRy, runs it on a mobile device, has been detailed through examples."}
{"id": "2512.00719", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00719", "abs": "https://arxiv.org/abs/2512.00719", "authors": ["Bohan Zhao", "Zane Cao", "Yongchao He"], "title": "SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed LLM Serving", "comment": null, "summary": "As large language models (LLMs) scale out with tensor parallelism (TP) and pipeline parallelism (PP) and production stacks have aggressively optimized the data plane (attention/GEMM and KV cache), sampling, the decision plane that turns logits into tokens, becomes a new bottleneck. This creates a structural holdout: sampling neither expands with TP nor balances across PP stages, so its share of iteration time grows as GPUs get faster and it caps pipeline frequency at the last stage. We present SIMPLE, a stage-agnostic, sequence-parallel, overlappable decision plane that disaggregates sampling into a CPU-side service and shrinks its runtime footprint back to a minor, hidden role. SIMPLE combines: (1) sequence-parallel sampling, which shards work along the batch dimension and removes vocabulary-axis collectives; (2) a CPU-based algorithm with column-wise penalties and truncation-first filtering to realize single-pass, linear-time kernels; and (3) speculative hot-vocab sampling (SHVS), which samples on a small hot set with rejection-correctness and uses a simple sizing model to choose the hot-vocab size that maximizes throughput. In evaluation, SIMPLE improves end-to-end throughput by up to 96% and reduces P95 latency by 20-65%. Crucially, SIMPLE requires no user-side code changes and composes with existing data-plane optimizations, unlocking scaling benefits that compound with future GPU generations."}
{"id": "2512.00259", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00259", "abs": "https://arxiv.org/abs/2512.00259", "authors": ["Diogo Ferreira", "Pedro Ribeiro", "André Coelho", "Rui Campos"], "title": "Design and Evaluation of a Multi-Agent Perception System for Autonomous Flying Networks", "comment": null, "summary": "Autonomous Flying Networks (FNs) are emerging as a key enabler of on-demand connectivity in dynamic and infrastructure-limited environments. However, current approaches mainly focus on UAV placement, routing, and resource management, neglecting the autonomous perception of users and their service demands - a critical capability for zero-touch network operation.\n  This paper presents the Multi-Agent Perception System (MAPS), a modular and scalable system that leverages multi-modal large language models (MM-LLMs) and agentic Artificial Intelligence (AI) to interpret visual and audio data collected by UAVs and generate Service Level Specifications (SLSs) describing user count, spatial distribution, and traffic demand. MAPS is evaluated using a synthetic multimodal emergency dataset, achieving user detection accuracies above 70% and SLS generation under 130 seconds in 90% of cases. Results demonstrate that combining audio and visual modalities enhances user detection and show that MAPS provides the perception layer required for autonomous, zero-touch FNs."}
{"id": "2512.00902", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00902", "abs": "https://arxiv.org/abs/2512.00902", "authors": ["Yebo Wu", "Jingguang Li", "Zhijiang Guo", "Li Li"], "title": "Elastic Mixture of Rank-Wise Experts for Knowledge Reuse in Federated Fine-Tuning", "comment": null, "summary": "Federated fine-tuning offers a promising solution for adapting Large Language Models (LLMs) to downstream tasks while safeguarding data privacy. However, its high computational and communication demands hinder its deployment on resource-constrained devices. In this paper, we propose SmartFed, a resource-efficient federated fine-tuning framework. SmartFed intelligently reuses knowledge embedded in existing LoRA modules, eliminating the need for expensive training from scratch when adapting LLMs to new tasks. To effectively exploit this knowledge and ensure scalability, we introduce the Mixture of Rank-Wise Experts (MoRE). MoRE decomposes LoRA modules into fine-grained rank-level experts. These experts are selectively activated and combined based on input semantics and resource budgets. Moreover, to optimize resource utilization, we present the Elastic Expert Quota Allocation (EEQA). EEQA adaptively allocates expert capacity across parameter matrices based on their contribution to model performance, focusing computing resources on the critical experts. Extensive evaluations across multiple benchmarks demonstrate that SmartFed significantly outperforms existing methods in model performance and training efficiency."}
{"id": "2512.00491", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00491", "abs": "https://arxiv.org/abs/2512.00491", "authors": ["Yule Han", "Kezhi Wang", "Kun Yang"], "title": "Smart-TCP: An Agentic AI-based Autonomous and Adaptive TCP Protocol", "comment": "Submitted for possible journal publication", "summary": "The Transmission Control Protocol (TCP) relies on a state machine and deterministic arithmetic to ensure reliable connections. However, traditional protocol logic driven by hard-coded state machines struggles to meet the demands of intelligent and autonomous network architectures. Here, we adopt the agentic AI-based paradigm, driven by Large Language Models (LLMs), characterized by context perception, autonomous reasoning, and tool use. Based on this, we propose Smart-TCP, which re-imagines TCP's core control logic as an autonomous agent. Specifically, the proposed architecture employs a context aggregation mechanism to synthesize the protocol context, utilizes the LLM for autonomous logical reasoning, and invokes an Arithmetic Logic Unit (ALU) as a tool for computation. Furthermore, we establish a dual-agent interaction framework based on this architecture and implement TCP protocol interactions. Experiments demonstrate that the Smart-TCP agent excels in static prediction and error detection, achieving a 93.33% success rate in end-to-end sessions. These results strongly validate the technical feasibility of an agentic AI-based TCP protocol."}
{"id": "2512.01039", "categories": ["cs.DC", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01039", "abs": "https://arxiv.org/abs/2512.01039", "authors": ["Aladin Djuhera", "Fernando Koch", "Alecio Binotto"], "title": "Joint Partitioning and Placement of Foundation Models for Real-Time Edge AI", "comment": null, "summary": "Inference over large-scale foundation models within heterogeneous edge environments necessitates a fundamentally reconfigurable orchestration substrate. Static partitioning of model layers presumes temporal stability across compute and network resources, which is misaligned with the volatility of real-world deployments. We introduce a framework in which both the spatial placement and internal segmentation of foundation models are elevated to runtime-resolved constructs. The orchestration problem is formalized as a constrained optimization over layer-wise assignments, subject to evolving latency, utilization, and privacy gradients. The framework implements reactive inference composition responsive to infrastructural fluctuations by integrating model-aware capacity profiling with dynamic graph re-partitioning and reallocation. We introduce architectural and algorithmic components, along with a representative use case in 6G multi-access edge computing."}
{"id": "2512.00509", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00509", "abs": "https://arxiv.org/abs/2512.00509", "authors": ["Sumita Majhi", "Kaushal Shelke", "Pinaki Mitra", "Ujjwal Biswas"], "title": "Improving Channel Estimation Through Gold Sequences", "comment": null, "summary": "This study evaluates Non-Orthogonal Multiple Access (NOMA) systems using Gold coding and Conventional-V-BLAST (C-V-BLAST). Superimposed signals on shared subcarriers make NOMA user separation difficult, unlike MIMO. Gold sequences' orthogonal features may enhance user separation and channel estimation. A novel channel estimation approach uses fractional power allocation and partially decoded data symbols. A realistic simulation environment was created using AWGN, Rayleigh fading, and shadowing. Using pilot signals, power allocation, and data symbols, our Channel Prediction Function (CPF) surpasses pilot-based techniques."}
{"id": "2512.01357", "categories": ["cs.DC", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.01357", "abs": "https://arxiv.org/abs/2512.01357", "authors": ["Wenbin Zhu", "Zhaoyan Shen", "Zili Shao", "Hongjun Dai", "Feng Chen"], "title": "Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity", "comment": null, "summary": "Serverless Large Language Models (LLMs) have emerged as a cost-effective solution for deploying AI services by enabling a 'pay-as-you-go' pricing model through GPU resource sharing. However, cold-start latency, especially the model loading phase, has become a critical performance bottleneck, as it scales linearly with model size and severely limits the practical deployment of large-scale LLM services. This paper presents Tangram, a novel system that accelerates Serverless LLM loading through efficient GPU memory reuse. By leveraging the unused GPU memory to retain model parameters, Tangram significantly reduces model transfer time and cold-start latency. Its design includes three key components: unified GPU memory pool for tensor-level parameter sharing across models, on-demand KV cache allocation for dynamic memory management, and GPU-affinity-aware scheduling for maximizing resource utilization. These techniques collectively address the critical challenges of inefficient memory usage and the cold-start problem in Serverless LLM platforms. We have implemented a fully functional prototype, and experiments show that Tangram achieves up to 6.2 times faster loading and reduces Time-To-First-Token (TTFT) during cold-start by 23--55% over state-of-the-art methods."}
{"id": "2512.00998", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.00998", "abs": "https://arxiv.org/abs/2512.00998", "authors": ["Christof Röhrig", "Benz Cramer"], "title": "LPWAN based IoT Architecture for Distributed Energy Monitoring in Deep Indoor Environments", "comment": null, "summary": "Continuous energy monitoring is essential for identifying potential savings and predicting the energy requirements of buildings. Energy meters are often located in underground spaces that are difficult to reach with wireless technology. This paper presents an experimental study comparing different Low Power Wide Area Networks (LPWAN) technologies in terms of building penetration and radio coverage. The technologies Low Power Long Range Wide Area Networks (LoRaWAN), Narrow Band Internet of Things (NB-IoT), Sigfox 0G and Wireless Smart Ubiquitous Networks (Wi-SUN) are evaluated experimentally. It also proposes a distributed hybrid IoT architecture that combines multiple LPWAN technologies using an abstraction layer to optimize cost and coverage. Communication is message-based using the publish-subscribe messaging pattern. It is implemented using the MQTT protocol. The abstraction layer decodes the proprietary binary data and converts it to a normalized JSON format."}
{"id": "2512.01549", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01549", "abs": "https://arxiv.org/abs/2512.01549", "authors": ["Tom Goethals", "Merlijn Sebrechts", "Stijn De Schrijver", "Filip De Turck", "Bruno Volckaert"], "title": "Delta Sum Learning: an approach for fast and global convergence in Gossip Learning", "comment": null, "summary": "Federated Learning is a popular approach for distributed learning due to its security and computational benefits. With the advent of powerful devices in the network edge, Gossip Learning further decentralizes Federated Learning by removing centralized integration and relying fully on peer to peer updates. However, the averaging methods generally used in both Federated and Gossip Learning are not ideal for model accuracy and global convergence. Additionally, there are few options to deploy Learning workloads in the edge as part of a larger application using a declarative approach such as Kubernetes manifests. This paper proposes Delta Sum Learning as a method to improve the basic aggregation operation in Gossip Learning, and implements it in a decentralized orchestration framework based on Open Application Model, which allows for dynamic node discovery and intent-driven deployment of multi-workload applications. Evaluation results show that Delta Sum performance is on par with alternative integration methods for 10 node topologies, but results in a 58% lower global accuracy drop when scaling to 50 nodes. Overall, it shows strong global convergence and a logarithmic loss of accuracy with increasing topology size compared to a linear loss for alternatives under limited connectivity."}
{"id": "2512.01035", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01035", "abs": "https://arxiv.org/abs/2512.01035", "authors": ["Shutong Chen", "Qi Liao", "Adnan Aijaz", "Yansha Deng"], "title": "Goal-Oriented Multi-Agent Semantic Networking: Unifying Intents, Semantics, and Intelligence", "comment": "Submitting to IEEE for potential publications", "summary": "6G services are evolving toward goal-oriented and AI-native communication, which are expected to deliver transformative societal benefits across various industries and promote energy sustainability. Yet today's networking architectures, built on complete decoupling of the applications and the network, cannot expose or exploit high-level goals, limiting their ability to adapt intelligently to service needs. This work introduces Goal-Oriented Multi-Agent Semantic Networking (GoAgentNet), a new architecture that elevates communication from data exchange to goal fulfilment. GoAgentNet enables applications and the network to collaborate by abstracting their functions into multiple collaborative agents, and jointly orchestrates multi-agent sensing, networking, computation, and control through semantic computation and cross-layer semantic networking, allowing the entire architecture to pursue unified application goals. We first outline the limitations of legacy network designs in supporting 6G services, based on which we highlight key enablers of our GoAgentNet design. Then, through three representative 6G usage scenarios, we demonstrate how GoAgentNet can unlock more efficient and intelligent services. We further identify unique challenges faced by GoAgentNet deployment and corresponding potential solutions. A case study on robotic fault detection and recovery shows that our GoAgentNet architecture improves energy efficiency by up to 99% and increases the task success rate by up to 72%, compared with the existing networking architectures without GoAgentNet, which underscores its potential to support scalable and sustainable 6G systems."}
{"id": "2512.01646", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.01646", "abs": "https://arxiv.org/abs/2512.01646", "authors": ["Barenya Kumar Nandy", "Rupesh Nasre"], "title": "StarDist: A Code Generator for Distributed Graph Algorithms", "comment": null, "summary": "Relational data, occurring in the real world, are often structured as graphs, which provide the logical abstraction required to make analytical derivations simpler. As graphs get larger, the irregular access patterns exhibited in most graph algorithms, hamper performance. This, along with NUMA and physical memory limits, results in scaling complexities with sequential/shared memory frameworks. StarPlat's MPI backend abstracts away the programmatic complexity involved in designing optimal distributed graph algorithms. It provides an instrument for coding graph algorithms that scale over distributed memory. In this work, we provide an analysis-transformation framework that leverages general semantics associated with iterations involving nodes and their neighbors, within StarPlat, to aggregate communication. The framework scans for patterns that warrant re-ordering in neighborhood access patterns, aggregate communication, and avoid communication altogether with opportunistic caching in reduction constructs. We also architect an optimized bulk-reduction substrate using Open MPI's passive Remote Memory Access (RMA) constructs. We applied our optimization logic to StarPlat's distributed backend and outperformed d-Galois by 2.05 and DRONE by 1.44 times in Single Source Shortest Paths across several big data graphs."}
{"id": "2512.01083", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.01083", "abs": "https://arxiv.org/abs/2512.01083", "authors": ["Fatih E. Bilgen", "A. Sila Okcu", "O. Tansel Baydas", "Ozgur B. Akan"], "title": "Internet of Intelligent Reflecting Surfaces (IoIRS)", "comment": "8 pages, 3 figures", "summary": "Intelligent Reflecting Surfaces (IRS) are anticipated to serve as a key cornerstone of future wireless networks, providing an unmatched capability to deterministically shape electromagnetic wave propagation. Despite this potential, most existing research still considers the IRS merely as a standalone physical-layer component, controlled by transmitters. However, as networks grow to encompass a massive number of these surfaces and a massive number of transmitters wishing to use them, this transmitter-centric design encounters substantial challenges. To overcome this challenge, we propose the Internet of IRS (IoIRS), an architecture that reconceives the IRS not just as a passive reflecting surface, but as a connected, hybrid entity functioning across both the physical layer and upper network layers. We present the conceptual framework and a preliminary protocol suite necessary to integrate these surfaces into the higher network layers. We conclude by examining how IoIRS architectures could be applied in practice, as their deployment will be essential for fully realizing the capabilities of future wireless networks."}
{"id": "2512.01764", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.01764", "abs": "https://arxiv.org/abs/2512.01764", "authors": ["Kingshuk Haldar"], "title": "Trace-based, time-resolved analysis of MPI application performance using standard metrics", "comment": "Presented at and submitted to the International Parallel Tools Workshop 2025", "summary": "Detailed trace analysis of MPI applications is essential for performance engineering, but growing trace sizes and complex communication behaviour often render comprehensive visual inspection impractical. This work presents a trace-based calculation of time-resolved values of standard MPI performance metrics, load balance, serialisation, and transfer efficiency, by discretising execution traces into fixed or adaptive time segments. The implementation processes Paraver traces postmortem, reconstructing critical execution paths and handling common event anomalies, such as clock inconsistencies and unmatched MPI events, to robustly calculate metrics for each segment. The calculated per-window metric values expose transient performance bottlenecks that the timeaggregated metrics from existing tools may conceal. Evaluations on a synthetic benchmark and real-world applications (LaMEM and ls1-MarDyn) demonstrate how time-resolved metrics reveal localised performance bottlenecks obscured by global aggregates, offering a lightweight and scalable alternative even when trace visualisation is impractical."}
{"id": "2512.01088", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01088", "abs": "https://arxiv.org/abs/2512.01088", "authors": ["Jingxiang Huang", "Samer Lahoud"], "title": "Physical-Layer Analysis of LoRa Robustness in the Presence of Narrowband Interference", "comment": null, "summary": "With the rapid development of Internet of Things (IoT) technologies, the sub-GHz unlicensed spectrum is increasingly being shared by protocols such as Long Range (LoRa), Sigfox, and Long-Range Frequency-Hopping Spread Spectrum (LR-FHSS). These protocols must coexist within the same frequency bands, leading to mutual interference. This paper investigates the physical-layer impact of two types of narrowband signals (BPSK and GMSK) on LoRa demodulation. We employ symbol-level Monte Carlo simulations to analyse how the interference-to-noise ratio (INR) affects the symbol error rate (SER) at a given signal-to-noise ratio (SNR) and noise floor, and then compare the results with those for additive white Gaussian noise (AWGN) of equal power. We demonstrate that modelling narrowband interference as additive white Gaussian noise (AWGN) systematically overestimates the SER of Chirp Spread Spectrum (CSS) demodulation. We also clarify the distinct impairment levels induced by AWGN and two types of narrowband interferers, and provide physical insight into the underlying mechanisms. Finally, we fit a two-segment function for the maximum INR that ensures correct demodulation across SNRs, with one segment for low SNR and the other for high SNR."}
{"id": "2512.00029", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00029", "abs": "https://arxiv.org/abs/2512.00029", "authors": ["Andreas Kouloumpris", "Georgios L. Stavrinides", "Maria K. Michael", "Theocharis Theocharides"], "title": "An optimization framework for task allocation in the edge/hub/cloud paradigm", "comment": "This version of the manuscript has been accepted for publication in Future Generation Computer Systems after peer review (Author Accepted Manuscript). It is not the final published version (Version of Record) and does not reflect any post-acceptance improvements. The Version of Record is available online at https://doi.org/10.1016/j.future.2024.02.005", "summary": "With the advent of the Internet of Things (IoT), novel critical applications have emerged that leverage the edge/hub/cloud paradigm, which diverges from the conventional edge computing perspective. A growing number of such applications require a streamlined architecture for their effective execution, often comprising a single edge device with sensing capabilities, a single hub device (e.g., a laptop or smartphone) for managing and assisting the edge device, and a more computationally capable cloud server. Typical examples include the utilization of an unmanned aerial vehicle (UAV) for critical infrastructure inspection or a wearable biomedical device (e.g., a smartwatch) for remote patient monitoring. Task allocation in this streamlined architecture is particularly challenging, due to the computational, communication, and energy limitations of the devices at the network edge. Consequently, there is a need for a comprehensive framework that can address the specific task allocation problem optimally and efficiently. To this end, we propose a complete, binary integer linear programming (BILP) based formulation for an application-driven design-time approach, capable of providing an optimal task allocation in the targeted edge/hub/cloud environment. The proposed method minimizes the desired objective, either the overall latency or overall energy consumption, while considering several crucial parameters and constraints often overlooked in related literature. We evaluate our framework using a real-world use-case scenario, as well as appropriate synthetic benchmarks. Our extensive experimentation reveals that the proposed approach yields optimal and scalable results, enabling efficient design space exploration for different applications and computational devices."}
{"id": "2512.01477", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01477", "abs": "https://arxiv.org/abs/2512.01477", "authors": ["Saso Nikolovski", "Pece Mitrevski"], "title": "Modeling and Simulation of Data Protection Systems for Business Continuity and Disaster Recovery", "comment": "17 pages, 11 figures, 9 tables", "summary": "In today's corporate landscape, particularly where operations rely heavily on information technologies, establishing a robust business continuity plan, including a disaster recovery strategy, is essential for ensuring swift recuperation following outages. This study presents a comparative analysis of recovery solutions, focusing on systems that operate partially or entirely within cloud environments and assessing their reliability in fulfilling organizational roles securely and dependably. Two such systems were deployed and evaluated in a real-world production setting. Key performance and reliability metrics were identified using simulation software to enhance these systems, alongside a System Dynamics analysis conducted for each. This work proposes a comprehensive framework for selecting and maintaining data protection and recovery solutions within organizational structures, outlining criteria for aligning chosen approaches with operational needs while adhering to predetermined timelines specified in business continuity and disaster recovery plans. The resulting analysis and findings offer actionable insights to guide decision-making when selecting appropriate recovery concepts."}
{"id": "2512.01571", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01571", "abs": "https://arxiv.org/abs/2512.01571", "authors": ["Xiao Xu", "Qiong Wu", "Pingyi Fan", "Kezhi Wang", "Nan Cheng", "Wen Chen", "Khaled B. Letaief"], "title": "Velocity-Adaptive Access Scheme for Semantic-Aware Vehicular Networks: Joint Fairness and AoI Optimization", "comment": "This paper has been submitted to IEEE transactions on moblie computing", "summary": "In this paper, we address the problem of fair access and Age of Information (AoI) optimization in 5G New Radio (NR) Vehicle to Everything (V2X) Mode 2. Specifically, vehicles need to exchange information with the road side unit (RSU). However, due to the varying vehicle speeds leading to different communication durations, the amount of data exchanged between different vehicles and the RSU may vary. This may poses significant safety risks in high-speed environments. To address this, we define a fairness index through tuning the selection window of different vehicles and consider the image semantic communication system to reduce latency. However, adjusting the selection window may affect the communication time, thereby impacting the AoI. Moreover, considering the re-evaluation mechanism in 5G NR, which helps reduce resource collisions, it may lead to an increase in AoI. We analyze the AoI using Stochastic Hybrid System (SHS) and construct a multi-objective optimization problem to achieve fair access and AoI optimization. Sequential Convex Approximation (SCA) is employed to transform the non-convex problem into a convex one, and solve it using convex optimization. We also provide a large language model (LLM) based algorithm. The scheme's effectiveness is validated through numerical simulations."}
{"id": "2512.01824", "categories": ["cs.NI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.01824", "abs": "https://arxiv.org/abs/2512.01824", "authors": ["Jéssica Consciência", "António Grilo"], "title": "HERMES: Heterogeneous Application-Enabled Routing Middleware for Edge-IoT Systems", "comment": "14 pages", "summary": "The growth of the Internet of Things has enabled a new generation of applications, pushing computation and intelligence toward the network edge. This trend, however, exposes challenges, as the heterogeneity of devices and the complex requirements of applications are often misaligned with the assumptions of traditional routing protocols, which lack the flexibility to accommodate application-layer metrics and policies. This work addresses this gap by proposing a software framework that enhances routing flexibility by dynamically incorporating application-aware decisions. The core of the work establishes a multi-hop Wi-Fi network of heterogeneous devices, specifically ESP8266, ESP32, and Raspberry Pi 3B. The routing layer follows a proactive approach, while the network is fault-tolerant, maintaining operation despite both node loss and message loss. On top of this, a middleware layer introduces three strategies for influencing routing behavior: two adapt the path a message traverses until arriving at the destination, while the third allows applications to shape the network topology. This layer offers a flexible interface for diverse applications. The framework was validated on a physical testbed through edge intelligence use cases, including distributing neural network inference computations across multiple devices and offloading the entire workload to the most capable node. Distributed inference is useful in scenarios requiring low latency, energy efficiency, privacy, and autonomy. Experimental results indicated that device heterogeneity significantly impacts network performance. Throughput and inference duration analysis showed the influence of the strategies on application behaviour, revealed that topology critically affects decentralized performance, and demonstrated the suitability of the framework for complex tasks."}
{"id": "2512.01829", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01829", "abs": "https://arxiv.org/abs/2512.01829", "authors": ["Salah Abdeljabar", "Marco Zennaro", "Mohamed-Slim Alouini"], "title": "Delay Tolerant Networking to Extend Connectivity in Rural Areas Using Public Transport Systems: Design And Analysis", "comment": null, "summary": "In today's digital age, access to the Internet is essential, yet a significant digital divide exists, particularly in rural areas of developing nations. This paper presents a Delay Tolerant Networking (DTN) framework that utilizes informal public transportation systems, such as minibus taxis, as mobile data mules to enhance connectivity in these underserved regions. We develop a probabilistic model to capture the randomness in vehicle mobility, including travel times and contact durations at bus stops. Key performance metrics are analyzed, including average data transmission rate and Peak Age of Information (PAoI), to assess the effectiveness of the proposed system. An analytical approximation for the Mean PAoI (MPAoI) is derived and validated through simulations. Case studies from real-world datasets in Nouakchott, Accra, and Addis Ababa demonstrate the practical applicability and scalability of our framework. The findings indicate that leveraging existing transportation networks can significantly bridge the digital divide by providing reliable internet-like connectivity to remote areas."}
{"id": "2512.01039", "categories": ["cs.DC", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01039", "abs": "https://arxiv.org/abs/2512.01039", "authors": ["Aladin Djuhera", "Fernando Koch", "Alecio Binotto"], "title": "Joint Partitioning and Placement of Foundation Models for Real-Time Edge AI", "comment": null, "summary": "Inference over large-scale foundation models within heterogeneous edge environments necessitates a fundamentally reconfigurable orchestration substrate. Static partitioning of model layers presumes temporal stability across compute and network resources, which is misaligned with the volatility of real-world deployments. We introduce a framework in which both the spatial placement and internal segmentation of foundation models are elevated to runtime-resolved constructs. The orchestration problem is formalized as a constrained optimization over layer-wise assignments, subject to evolving latency, utilization, and privacy gradients. The framework implements reactive inference composition responsive to infrastructural fluctuations by integrating model-aware capacity profiling with dynamic graph re-partitioning and reallocation. We introduce architectural and algorithmic components, along with a representative use case in 6G multi-access edge computing."}

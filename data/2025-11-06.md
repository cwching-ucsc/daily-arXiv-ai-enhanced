<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots](https://arxiv.org/abs/2511.03286)
*Ehud Shapiro*

Main category: cs.DC

TL;DR: The paper introduces a formal framework—atomic-transactions multiagent transition systems—to model global digital platforms, defines "essential agents" (minimal agent sets whose removal breaks communication), and shows counting essential agents partitions platforms into four classes: centralised (1), decentralised (>1 finite), federated (infinite but not universal), and grassroots (universal). It provides formal specifications and correctness proofs for a social-network example and argues grassroots platforms, as previously defined, imply universality of essential agents.


<details>
  <summary>Details</summary>
Motivation: Provide a precise mathematical framework to classify and reason about global digital platforms (servers, p2p systems, federations, grassroots) and to compare architectures using formal properties rather than informal descriptions.

Method: Define multiagent transition systems with atomic transactions, formalize "essential agents", prove that the cardinality of minimal essential-agent sets yields a four-way partition, and instantiate the framework with formal specifications and proofs for a social-network use case; discuss other platform types informally.

Result: A provable four-class taxonomy of global platforms; formal atomic-transaction specifications for centralised, decentralised, federated, and grassroots social-network variants; proof that earlier grassroots definitions entail that all agents are essential, placing them in a distinct class.

Conclusion: The framework gives a first systematic mathematical method to classify any global platform by writing a multiagent atomic-transaction specification and computing the minimal essential-agent cardinality; it clarifies and unifies several informal notions and locates grassroots platforms distinctly.

Abstract: Global digital platforms are software systems designed to serve entire
populations, with some already serving billions of people. We propose atomic
transactions-based multiagent transition systems and protocols as a formal
framework to study them; introduce essential agents -- minimal sets of agents
the removal of which makes communication impossible; and show that the
cardinality of essential agents partitions all global platforms into four
classes:
  1. Centralised -- one (the server)
  2. Decentralised -- finite $>1$ (bootstrap nodes)
  3. Federated -- infinite but not universal (all servers)
  4. Grassroots -- universal (all agents)
  Our illustrative formal example is a global social network, for which we
provide centralised, decentralised, federated, and grassroots specifications
via multiagent atomic transactions, and prove they satisfy basic correctness
properties. We discuss informally additional global platforms -- currencies,
``sharing economy'' apps, AI, and more. While this may be the first
characterisation of centralised, decentralised, and federated global platforms,
grassroots platforms have been formally defined previously, but using different
notions. Here, we prove that their original definition implies that all agents
are essential, placing grassroots platforms in a distinct class within the
broader formal context that includes all global platforms. This work provides
the first mathematical framework for classifying any global platform --
existing or imagined -- by providing a multiagent atomic-transactions
specification of it and determining the cardinality of the minimal set of
essential agents in the ensuing multiagent protocol. It thus

</details>


### [2] [UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM](https://arxiv.org/abs/2511.03293)
*Hai Huang,Xuhong Qiang,Weisheng Zhao,Chenchen Liu*

Main category: cs.DC

TL;DR: UMDAM is a unified data layout and DRAM address-mapping scheme that aligns NPU and PIM memory layouts (column-major, tile-based + configurable DRAM mapping) so NPU-PIM co-execution avoids layout mismatch, bandwidth loss and redundant storage, achieving up to 3.0x TTFT and 2.18x TTLT speedups on OPT models without extra memory overhead.


<details>
  <summary>Details</summary>
Motivation: LLM decoding on edge devices is memory- bound; NPUs and PIMs have different data layout/access patterns leading to inefficient data movement, bandwidth loss, and duplicated storage when co-executing. A layout and address-mapping scheme that is simultaneously friendly to both NPU computation and PIM access can unlock performance and latency improvements.

Method: Design a column-major, tile-based memory layout that matches NPU compute locality while enabling efficient PIM operations. Add a configurable DRAM address mapping layer that maps tiles to DRAM banks/rows to maximize PIM bandwidth and avoid bank conflicts, all without extra memory copies or storage overhead. The scheme is applied at data- layout and address-translation time so that NPU and PIM can co-execute directly on shared buffers.

Result: On a suite of OPT models, UMDAM reduces time-to-first-token (TTFT) by up to 3.0x and time-to-last-token (TTLT) by up to 2.18x, demonstrating substantial end-to-end inference latency improvements for edge LLM decoding workloads.

Conclusion: UMDAM effectively resolves layout and DRAM mapping mismatches in NPU-PIM co-execution, enabling large latency reductions for LLM decoding on edge devices without additional memory or bandwidth penalty. Future work could extend evaluations to more model families, power/energy metrics, and hardware prototypes.

Abstract: Large Language Models (LLMs) are increasingly deployed on edge devices with
Neural Processing Units (NPUs), yet the decode phase remains memory-intensive,
limiting performance. Processing-in-Memory (PIM) offers a promising solution,
but co-executing NPU-PIM systems face challenges such as data layout
mismatches, bandwidth loss, and redundant storage. To address these issues, we
propose UMDAM, a unified memory-affinity data layout and DRAM address mapping
scheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,
tile-based layout and a configurable DRAM mapping strategy to ensure
compatibility with NPU computation while maximizing PIM efficiency -- without
introducing extra memory overhead or bandwidth loss. Comprehensive evaluations
on OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up
to 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving
end-to-end LLM inference efficiency on edge devices.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [3] [Distributed Incast Detection in Data Center Networks](https://arxiv.org/abs/2511.03039)
*Yiming Zheng,Haoran Qi,Lirui Yu,Zhan Shu,Qing Zhao*

Main category: cs.NI

TL;DR: Proposes a switch-level distributed incast detector using a probabilistic hypothesis test on new-flow arrival intervals, enabling immediate per-flow classification with an optimal threshold; outperforms queue-length based methods in speed and accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing incast detectors use fixed thresholds on egress queue lengths or gradients, causing delayed detection and high error rates during microbursts in data centers. A faster, more accurate detection that can act from the first packet is needed.

Method: Analyze inter-arrival intervals of new flows at each switch and apply a probabilistic hypothesis test with a derived optimal detection threshold to decide if a flow belongs to an incast. Detection is performed per-flow using only initial packet timing, enabling distributed switch-level operation.

Result: Experimental evaluation shows substantial gains over MA-ECN, BurstRadar, and Pulser in detection latency and inference accuracy, with immediate classification from the first packet and lower false positives/negatives.

Conclusion: Interval-based probabilistic detection offers faster, more accurate incast detection than queue-length threshold methods, enabling prompt mitigation and improved data center performance.

Abstract: Incast traffic in data centers can lead to severe performance degradation,
such as packet loss and increased latency. Effectively addressing incast
requires prompt and accurate detection. Existing solutions, including MA-ECN,
BurstRadar and Pulser, typically rely on fixed thresholds of switch port egress
queue lengths or their gradients to identify microburst caused by incast flows.
However, these queue length related methods often suffer from delayed detection
and high error rates. In this study, we propose a distributed incast detection
method for data center networks at the switch-level, leveraging a probabilistic
hypothesis test with an optimal detection threshold. By analyzing the arrival
intervals of new flows, our algorithm can immediately determine if a flow is
part of an incast traffic from its initial packet. The experimental results
demonstrate that our method offers significant improvements over existing
approaches in both detection speed and inference accuracy.

</details>


### [4] [Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing](https://arxiv.org/abs/2511.03159)
*Shuting Qiu,Fang Dong,Siyu Tan,Ruiting Zhou,Dian Shen,Patrick P. C. Lee,Qilin Fan*

Main category: cs.NI

TL;DR: The paper proposes splitting DNNs into interrelated submodels for fine-grained caching at mobile edge servers and formulates a joint caching-and-routing optimization; it introduces CoCaR (LP + random rounding) and an online variant CoCaR-OL, showing large QoE/inference-precision gains in simulations.


<details>
  <summary>Details</summary>
Motivation: MEC can reduce latency by pre-caching DNNs, but edge capacity is limited and model loading time (affecting QoE) is underexplored. By using dynamic DNNs (disassembled submodels), the system can cache parts of models and route requests more flexibly to balance inference precision and loading latency.

Method: Formulate a joint optimization problem to maximize user request inference precision subject to server resource, latency, and loading-time constraints. Propose CoCaR: an offline algorithm that solves a linear-program relaxation and applies randomized rounding to obtain near-optimal caching and routing decisions. Develop CoCaR-OL as an online adaptation to handle dynamic, unpredictable request patterns.

Result: Simulations show CoCaR increases average request inference precision by 46% over state-of-the-art baselines. In online settings, CoCaR-OL improves user QoE by at least 32.3% compared to competitive baselines.

Conclusion: Dynamic DNN decomposition combined with optimization-based caching and routing (CoCaR/CoCaR-OL) offers substantial QoE and precision improvements in MEC settings; the offline algorithm is near-optimal and the online variant adapts effectively to request dynamics.

Abstract: Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near
end-users, providing low-latency services and improving users' quality of
experience (QoE). However, caching all DNN models at edge servers with limited
capacity is difficult, and the impact of model loading time on QoE remains
underexplored. Hence, we introduce dynamic DNNs in edge scenarios,
disassembling a complete DNN model into interrelated submodels for more
fine-grained and flexible model caching and request routing solutions. This
raises the pressing issue of jointly deciding request routing and submodel
caching for dynamic DNNs to balance model inference precision and loading
latency for QoE optimization. In this paper, we study the joint dynamic model
caching and request routing problem in MEC networks, aiming to maximize user
request inference precision under constraints of server resources, latency, and
model loading time. To tackle this problem, we propose CoCaR, an offline
algorithm based on linear programming and random rounding that leverages
dynamic DNNs to optimize caching and routing schemes, achieving near-optimal
performance. Furthermore, we develop an online variant of CoCaR, named
CoCaR-OL, enabling effective adaptation to dynamic and unpredictable online
request patterns. The simulation results demonstrate that the proposed CoCaR
improves the average inference precision of user requests by 46\% compared to
state-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves
an improvement of no less than 32.3\% in user QoE over competitive baselines.

</details>

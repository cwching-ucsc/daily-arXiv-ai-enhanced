<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Performance Comparison of 5G NR Uplink MIMO and Uplink Carrier Aggregations on Commercial Network](https://arxiv.org/abs/2511.16751)
*Henry Shao,Kasidis Arunruangsirilert*

Main category: cs.NI

TL;DR: This paper evaluates uplink throughput of UL-MIMO and UL-CA on a commercial T-Mobile 5G network (SA) across various RF conditions and transport modes. It finds UL-MIMO often yields slower uplink throughput than UL-CA except in strong RF conditions where UL-MIMO performs adequately, suggesting UL-CA be reserved for weak-RF UEs to conserve capacity.


<details>
  <summary>Details</summary>
Motivation: Uplink demand is growing due to social media, high-resolution content, IoT and FWA, motivating deployment of UL-MIMO and UL-CA on commercial 5G networks. The study aims to characterize real-world uplink throughput behavior of these technologies on a large operator's SA network.

Method: Empirical throughput measurements were taken on T-Mobile’s commercial 5G network (n41 TDD and mixed TDD/FDD CA) across a variety of RF environments and transportation modes to compare UL-MIMO (two data streams on one band) against UL-CA (aggregation across bands).

Result: Despite theoretical efficiency gains from UL-MIMO, measurements show UL-MIMO often yields lower uplink throughput than UL-CA in most tested scenarios. In strong RF conditions UL-MIMO provides acceptable user experience, so the authors propose using UL-CA for UEs in weaker RF to preserve capacity.

Conclusion: UL-MIMO is not universally superior in practice; network operators should consider RF conditions when assigning UL-MIMO vs UL-CA. Reserving UL-CA for weak-RF UEs can conserve capacity while maintaining user experience.

Abstract: Demands for uplink on mobile networks are increasing with the rapid development of social media platforms, 4K/8K content creation, IoT applications, and Fixed Wireless Access (FWA) broadband. As a result, Uplink MIMO (UL-MIMO) and Uplink Carrier Aggregation (UL-CA) have been widely deployed for the first time on commercial 5G networks. UL-MIMO enables the transmission of two data streams on one frequency band in strong RF conditions, theoretically doubling throughput and efficiency. On the other hand, UL-CA allows for simultaneous upload on greater channel widths, allowing more resources to be assigned to a single UE for higher throughput. In the United States, T-Mobile USA, a mobile network operator (MNO), has deployed network-wide 5G Standalone (SA), along with UL-MIMO on Time Division Duplex (TDD) band n41 and UL-CA between TDD and Frequency Division Duplex (FDD) NR bands. In this paper, the uplink throughput performance of UL-MIMO and UL-CA will be evaluated on the commercial T-Mobile 5G network on a variety of RF environments and modes of transportation. It was found that, even with the efficiency gains, UL-MIMO yields slower uplink throughput in most scenarios. However, in stronger RF conditions, UL-MIMO can provide an adequate user experience, so capacity can be conserved by reserving UL-CA for UE in weaker RF conditions.

</details>


### [2] [A streaming algorithm and hardware accelerator for top-K flow detection in network traffic](https://arxiv.org/abs/2511.16797)
*Carolina Gallardo-Pavesi,Yaime Fernández,Javier E. Soto,Cecilia Hernández,Miguel Figueroa*

Main category: cs.NI

TL;DR: Proposes a hardware-accelerated top-K flow identification algorithm that combines a modified TowerSketch with a priority queue array; achieves high precision (>0.94) and low relative error (<1.96%) for K up to 32,768 on real traces and runs at one packet per cycle on an AMD VirtexU280 FPGA (392 MHz, >200 Gbps).


<details>
  <summary>Details</summary>
Motivation: Top-K flow identification is critical for flow scheduling and anomaly detection but is hard at high line rates and large flow counts due to limited on-chip memory on hardware accelerators. Existing sketch algorithms trade accuracy for memory and can perform poorly on skewed traffic distributions.

Method: Design a modified TowerSketch tailored for frequency estimation and combine it with a hardware-friendly priority queue array to track candidates for the top-K flows. Implement the complete accelerator on an AMD VirtexU280 UltraScale+ FPGA and evaluate on real traffic traces.

Result: On real traces, the system identifies top-K flows for K up to 32,768 with precision >0.94 and average relative frequency error <1.96%. The FPGA implementation processes one packet per cycle at 392 MHz, achieving a minimum line rate exceeding 200 Gbps.

Conclusion: The combined sketch + priority-queue design provides accurate top-K identification at high line rates within the memory constraints of FPGA hardware, making it a viable solution for real-time network monitoring and flow-aware tasks.

Abstract: Identifying the largest K flows in network traffic is an important task for applications such as flow scheduling and anomaly detection, which aim to improve network efficiency and security. However, accurately estimating flow frequencies is challenging due to the large number of flows and increasing network speeds. Hardware accelerators are often used in this endeavor due to their high computational power, but their limited amount of on-chip memory constrains their performance. Various sketch-based algorithms have been proposed to estimate properties of traffic such as frequency, with lower memory usage and theoretical bounds, but they often under perform with the skewed distribution of network traffic. In this work, we propose an algorithm for top-K identification using a modified TowerSketch and a priority queue array. Tested on real traffic traces, we identify the top-K flows, with K up to 32,768, with a precision of more than 0.94, and estimate their frequency with an average relative error under 1.96%. We designed and implemented an accelerator for this algorithm on an AMD VirtexU280 UltraScale+ FPGA, which processes one packet per cycle at392 MHz, reaching a minimum line rate of more than 200 Gbps.

</details>


### [3] [Adaptive Receiver-Side Scheduling for Smooth Interactive Delivery](https://arxiv.org/abs/2511.16902)
*Michael Luby*

Main category: cs.NI

TL;DR: Proposes a lightweight receiver-side scheduler that regularizes object release timing by tracking an adaptive upper-envelope of effective path delay and adjusting releases asymmetrically (fast for late arrivals, slow for early ones). Implemented modularly within the BitRipple Tunnel overlay, it eliminates large jitter excursions on a cloud‑gaming workload with minimal added latency and requires no sender feedback or clock sync.


<details>
  <summary>Details</summary>
Motivation: Network delay variation and receiver-side recovery dynamics distort steady arrival cadence needed by interactive applications (cloud gaming, XR, real-time inference), causing visible jitter and stalls even when transports deliver packets correctly. A receiver-only solution that stabilizes output timing without protocol changes or synchronization is needed.

Method: A receiver-side scheduler maintains an adaptive estimate of path delay that acts as an upper-envelope over recent delay peaks. It shifts release times asymmetrically: react quickly to late arrivals (to avoid stalls) and only slowly to early arrivals (to avoid reducing buffer headroom), thereby keeping release aligned with recent peaks. Integrated as an independent module into the BitRipple Tunnel overlay; no transport or sender modifications, runs on receiver clock.

Result: On a cloud-gaming workload within BRT, the scheduler removed most large jitter excursions and produced tightly clustered release intervals, improving visible smoothness. Additional latency improvements are observed due to the BRT overlay behaviour. The approach is modular and could be added to transport stacks (TCP/QUIC/WebRTC/UDP/RTP) in future work.

Conclusion: Receiver-side scheduling using an adaptive upper-envelope delay estimate is an effective, low-complexity way to smooth object release timing at the receiver, reducing visible jitter with minimal latency overhead and without requiring feedback or clock synchronization; it can be deployed modularly in overlays or transport stacks.

Abstract: Interactive applications such as cloud gaming, XR streaming, and real-time inference depend on data objects arriving at a steady cadence. In practice, network delay variation and recovery dynamics at the receiver distort this cadence even when transports deliver all packets correctly, which produces visible jitter, stalls, and unstable playback.
  We present a lightweight receiver-side scheduling approach that regularizes release timing after recovery. The scheduler maintains an adaptive estimate of effective path delay and adjusts release times asymmetrically, responding quickly to late arrivals and only gradually to early ones. This upper-envelope behavior keeps release aligned with recent delay peaks and maintains smooth playback with minimal added latency. The scheduler runs entirely on the receiver clock and requires no feedback or synchronization.
  As a concrete example, we integrate receiver-side scheduling into the BitRipple Tunnel (BRT) overlay, an application-layer software system that forwards traffic without altering the underlying transport protocol. Within BRT, the scheduler functions as an independent module that regulates delivery timing for forwarded objects.
  Evaluating BRT with receiver-side scheduling on a cloud-gaming workload shows that the scheduler removes virtually all large jitter excursions and yields tightly clustered release intervals that improve visible smoothness. Broader latency improvements arise from the behavior of the full BRT overlay. Receiver-side scheduling can also be integrated modularly into transport stacks such as TCP, QUIC, WebRTC, UDP, or RTP, which are natural deployment points for future work.

</details>

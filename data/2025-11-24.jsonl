{"id": "2511.16751", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16751", "abs": "https://arxiv.org/abs/2511.16751", "authors": ["Henry Shao", "Kasidis Arunruangsirilert"], "title": "Performance Comparison of 5G NR Uplink MIMO and Uplink Carrier Aggregations on Commercial Network", "comment": "IEEE Consumer Communications & Networking Conference 2026 (IEEE CCNC 2026), 9-12 January 2026, Las Vegas, NV, USA", "summary": "Demands for uplink on mobile networks are increasing with the rapid development of social media platforms, 4K/8K content creation, IoT applications, and Fixed Wireless Access (FWA) broadband. As a result, Uplink MIMO (UL-MIMO) and Uplink Carrier Aggregation (UL-CA) have been widely deployed for the first time on commercial 5G networks. UL-MIMO enables the transmission of two data streams on one frequency band in strong RF conditions, theoretically doubling throughput and efficiency. On the other hand, UL-CA allows for simultaneous upload on greater channel widths, allowing more resources to be assigned to a single UE for higher throughput. In the United States, T-Mobile USA, a mobile network operator (MNO), has deployed network-wide 5G Standalone (SA), along with UL-MIMO on Time Division Duplex (TDD) band n41 and UL-CA between TDD and Frequency Division Duplex (FDD) NR bands. In this paper, the uplink throughput performance of UL-MIMO and UL-CA will be evaluated on the commercial T-Mobile 5G network on a variety of RF environments and modes of transportation. It was found that, even with the efficiency gains, UL-MIMO yields slower uplink throughput in most scenarios. However, in stronger RF conditions, UL-MIMO can provide an adequate user experience, so capacity can be conserved by reserving UL-CA for UE in weaker RF conditions."}
{"id": "2511.16797", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16797", "abs": "https://arxiv.org/abs/2511.16797", "authors": ["Carolina Gallardo-Pavesi", "Yaime Fernández", "Javier E. Soto", "Cecilia Hernández", "Miguel Figueroa"], "title": "A streaming algorithm and hardware accelerator for top-K flow detection in network traffic", "comment": "8 pages, 5 figures, to be published in 2025 28th Euromicro Conference on Digital System Design (DSD)", "summary": "Identifying the largest K flows in network traffic is an important task for applications such as flow scheduling and anomaly detection, which aim to improve network efficiency and security. However, accurately estimating flow frequencies is challenging due to the large number of flows and increasing network speeds. Hardware accelerators are often used in this endeavor due to their high computational power, but their limited amount of on-chip memory constrains their performance. Various sketch-based algorithms have been proposed to estimate properties of traffic such as frequency, with lower memory usage and theoretical bounds, but they often under perform with the skewed distribution of network traffic. In this work, we propose an algorithm for top-K identification using a modified TowerSketch and a priority queue array. Tested on real traffic traces, we identify the top-K flows, with K up to 32,768, with a precision of more than 0.94, and estimate their frequency with an average relative error under 1.96%. We designed and implemented an accelerator for this algorithm on an AMD VirtexU280 UltraScale+ FPGA, which processes one packet per cycle at392 MHz, reaching a minimum line rate of more than 200 Gbps."}
{"id": "2511.16902", "categories": ["cs.NI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.16902", "abs": "https://arxiv.org/abs/2511.16902", "authors": ["Michael Luby"], "title": "Adaptive Receiver-Side Scheduling for Smooth Interactive Delivery", "comment": "25 pages, 6 figures, 1 table", "summary": "Interactive applications such as cloud gaming, XR streaming, and real-time inference depend on data objects arriving at a steady cadence. In practice, network delay variation and recovery dynamics at the receiver distort this cadence even when transports deliver all packets correctly, which produces visible jitter, stalls, and unstable playback.\n  We present a lightweight receiver-side scheduling approach that regularizes release timing after recovery. The scheduler maintains an adaptive estimate of effective path delay and adjusts release times asymmetrically, responding quickly to late arrivals and only gradually to early ones. This upper-envelope behavior keeps release aligned with recent delay peaks and maintains smooth playback with minimal added latency. The scheduler runs entirely on the receiver clock and requires no feedback or synchronization.\n  As a concrete example, we integrate receiver-side scheduling into the BitRipple Tunnel (BRT) overlay, an application-layer software system that forwards traffic without altering the underlying transport protocol. Within BRT, the scheduler functions as an independent module that regulates delivery timing for forwarded objects.\n  Evaluating BRT with receiver-side scheduling on a cloud-gaming workload shows that the scheduler removes virtually all large jitter excursions and yields tightly clustered release intervals that improve visible smoothness. Broader latency improvements arise from the behavior of the full BRT overlay. Receiver-side scheduling can also be integrated modularly into transport stacks such as TCP, QUIC, WebRTC, UDP, or RTP, which are natural deployment points for future work."}
{"id": "2511.16966", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16966", "abs": "https://arxiv.org/abs/2511.16966", "authors": ["Yiheng Bian", "Zechen Li", "Lanqing Yang", "Hao Pan", "Yezhou Wang", "Longyuan Ge", "Jeffery Wu", "Ruiheng Liu", "Yongjian Fu", "Yichao chen", "Guangtao xue"], "title": "One Walk is All You Need: Data-Efficient 3D RF Scene Reconstruction with Human Movements", "comment": null, "summary": "Reconstructing 3D Radiance Field (RF) scenes through opaque obstacles is a long-standing goal, yet it is fundamentally constrained by a laborious data acquisition process requiring thousands of static measurements, which treats human motion as noise to be filtered. This work introduces a new paradigm with a core objective: to perform fast, data-efficient, and high-fidelity RF reconstruction of occluded 3D static scenes, using only a single, brief human walk. We argue that this unstructured motion is not noise, but is in fact an information-rich signal available for reconstruction. To achieve this, we design a factorization framework based on composite 3D Gaussian Splatting (3DGS) that learns to model the dynamic effects of human motion from the persistent static scene geometry within a raw RF stream. Trained on just a single 60-second casual walk, our model reconstructs the full static scene with a Structural Similarity Index (SSIM) of 0.96, remarkably outperforming heavily-sampled state-of-the-art (SOTA) by 12%. By transforming the human movements into its valuable signals, our method eliminates the data acquisition bottleneck and paves the way for on-the-fly 3D RF mapping of unseen environments."}
{"id": "2511.16947", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.16947", "abs": "https://arxiv.org/abs/2511.16947", "authors": ["Chenqi Zhao", "Wenfei Wu", "Linhai Song", "Yuchen Xu"], "title": "MicroMoE: Fine-Grained Load Balancing for Mixture-of-Experts with Token Scheduling", "comment": "19 pages", "summary": "Mixture-of-Experts (MoE) has emerged as a promising approach to scale up deep learning models due to its significant reduction in computational resources. However, the dynamic nature of MoE leads to load imbalance among experts, severely impacting training efficiency. While previous research has attempted to address the load balancing challenge, existing solutions either compromise model accuracy or introduce additional system overhead. As a result, they fail to achieve fine-grained load balancing, which is crucial to optimizing training efficiency.\n  We propose MicroEP, a novel parallelization strategy to achieve fine-grained load balancing in MoE systems. MicroEP is capable of achieving optimal load balancing in every micro-batch through efficient token scheduling across GPUs. Furthermore, we propose MicroMoE, an efficient distributed MoE training system with MicroEP's load balancing capabilities. Our experimental results demonstrate that MicroMoE improves the end-to-end training throughput by up to 47.6% compared with the state-of-the-art system, and almost consistently achieves optimal load balance among GPUs."}
{"id": "2511.17119", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.17119", "abs": "https://arxiv.org/abs/2511.17119", "authors": ["Gabriel Job Antunes Grabher", "Fumio Machida", "Thomas Ropars"], "title": "Modeling Anomaly Detection in Cloud Services: Analysis of the Properties that Impact Latency and Resource Consumption", "comment": null, "summary": "Detecting and resolving performance anomalies in Cloud services is crucial for maintaining desired performance objectives. Scaling actions triggered by an anomaly detector help achieve target latency at the cost of extra resource consumption. However, performance anomaly detectors make mistakes. This paper studies which characteristics of performance anomaly detection are important to optimize the trade-off between performance and cost. Using Stochastic Reward Nets, we model a Cloud service monitored by a performance anomaly detector. Using our model, we study the impact of detector characteristics, namely precision, recall and inspection frequency, on the average latency and resource consumption of the monitored service. Our results show that achieving a high precision and a high recall is not always necessary. If detection can be run frequently, a high precision is enough to obtain a good performance-to-cost trade-off, but if the detector is run infrequently, recall becomes the most important."}

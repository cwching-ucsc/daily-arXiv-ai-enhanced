{"id": "2511.03039", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03039", "abs": "https://arxiv.org/abs/2511.03039", "authors": ["Yiming Zheng", "Haoran Qi", "Lirui Yu", "Zhan Shu", "Qing Zhao"], "title": "Distributed Incast Detection in Data Center Networks", "comment": null, "summary": "Incast traffic in data centers can lead to severe performance degradation,\nsuch as packet loss and increased latency. Effectively addressing incast\nrequires prompt and accurate detection. Existing solutions, including MA-ECN,\nBurstRadar and Pulser, typically rely on fixed thresholds of switch port egress\nqueue lengths or their gradients to identify microburst caused by incast flows.\nHowever, these queue length related methods often suffer from delayed detection\nand high error rates. In this study, we propose a distributed incast detection\nmethod for data center networks at the switch-level, leveraging a probabilistic\nhypothesis test with an optimal detection threshold. By analyzing the arrival\nintervals of new flows, our algorithm can immediately determine if a flow is\npart of an incast traffic from its initial packet. The experimental results\ndemonstrate that our method offers significant improvements over existing\napproaches in both detection speed and inference accuracy.", "AI": {"tldr": "Proposes a switch-level distributed incast detector using a probabilistic hypothesis test on new-flow arrival intervals, enabling immediate per-flow classification with an optimal threshold; outperforms queue-length based methods in speed and accuracy.", "motivation": "Existing incast detectors use fixed thresholds on egress queue lengths or gradients, causing delayed detection and high error rates during microbursts in data centers. A faster, more accurate detection that can act from the first packet is needed.", "method": "Analyze inter-arrival intervals of new flows at each switch and apply a probabilistic hypothesis test with a derived optimal detection threshold to decide if a flow belongs to an incast. Detection is performed per-flow using only initial packet timing, enabling distributed switch-level operation.", "result": "Experimental evaluation shows substantial gains over MA-ECN, BurstRadar, and Pulser in detection latency and inference accuracy, with immediate classification from the first packet and lower false positives/negatives.", "conclusion": "Interval-based probabilistic detection offers faster, more accurate incast detection than queue-length threshold methods, enabling prompt mitigation and improved data center performance."}}
{"id": "2511.03159", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.03159", "abs": "https://arxiv.org/abs/2511.03159", "authors": ["Shuting Qiu", "Fang Dong", "Siyu Tan", "Ruiting Zhou", "Dian Shen", "Patrick P. C. Lee", "Qilin Fan"], "title": "Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing", "comment": null, "summary": "Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near\nend-users, providing low-latency services and improving users' quality of\nexperience (QoE). However, caching all DNN models at edge servers with limited\ncapacity is difficult, and the impact of model loading time on QoE remains\nunderexplored. Hence, we introduce dynamic DNNs in edge scenarios,\ndisassembling a complete DNN model into interrelated submodels for more\nfine-grained and flexible model caching and request routing solutions. This\nraises the pressing issue of jointly deciding request routing and submodel\ncaching for dynamic DNNs to balance model inference precision and loading\nlatency for QoE optimization. In this paper, we study the joint dynamic model\ncaching and request routing problem in MEC networks, aiming to maximize user\nrequest inference precision under constraints of server resources, latency, and\nmodel loading time. To tackle this problem, we propose CoCaR, an offline\nalgorithm based on linear programming and random rounding that leverages\ndynamic DNNs to optimize caching and routing schemes, achieving near-optimal\nperformance. Furthermore, we develop an online variant of CoCaR, named\nCoCaR-OL, enabling effective adaptation to dynamic and unpredictable online\nrequest patterns. The simulation results demonstrate that the proposed CoCaR\nimproves the average inference precision of user requests by 46\\% compared to\nstate-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves\nan improvement of no less than 32.3\\% in user QoE over competitive baselines.", "AI": {"tldr": "The paper proposes splitting DNNs into interrelated submodels for fine-grained caching at mobile edge servers and formulates a joint caching-and-routing optimization; it introduces CoCaR (LP + random rounding) and an online variant CoCaR-OL, showing large QoE/inference-precision gains in simulations.", "motivation": "MEC can reduce latency by pre-caching DNNs, but edge capacity is limited and model loading time (affecting QoE) is underexplored. By using dynamic DNNs (disassembled submodels), the system can cache parts of models and route requests more flexibly to balance inference precision and loading latency.", "method": "Formulate a joint optimization problem to maximize user request inference precision subject to server resource, latency, and loading-time constraints. Propose CoCaR: an offline algorithm that solves a linear-program relaxation and applies randomized rounding to obtain near-optimal caching and routing decisions. Develop CoCaR-OL as an online adaptation to handle dynamic, unpredictable request patterns.", "result": "Simulations show CoCaR increases average request inference precision by 46% over state-of-the-art baselines. In online settings, CoCaR-OL improves user QoE by at least 32.3% compared to competitive baselines.", "conclusion": "Dynamic DNN decomposition combined with optimization-based caching and routing (CoCaR/CoCaR-OL) offers substantial QoE and precision improvements in MEC settings; the offline algorithm is near-optimal and the online variant adapts effectively to request dynamics."}}
{"id": "2511.03286", "categories": ["cs.DC", "cs.MA", "cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.03286", "abs": "https://arxiv.org/abs/2511.03286", "authors": ["Ehud Shapiro"], "title": "Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots", "comment": null, "summary": "Global digital platforms are software systems designed to serve entire\npopulations, with some already serving billions of people. We propose atomic\ntransactions-based multiagent transition systems and protocols as a formal\nframework to study them; introduce essential agents -- minimal sets of agents\nthe removal of which makes communication impossible; and show that the\ncardinality of essential agents partitions all global platforms into four\nclasses:\n  1. Centralised -- one (the server)\n  2. Decentralised -- finite $>1$ (bootstrap nodes)\n  3. Federated -- infinite but not universal (all servers)\n  4. Grassroots -- universal (all agents)\n  Our illustrative formal example is a global social network, for which we\nprovide centralised, decentralised, federated, and grassroots specifications\nvia multiagent atomic transactions, and prove they satisfy basic correctness\nproperties. We discuss informally additional global platforms -- currencies,\n``sharing economy'' apps, AI, and more. While this may be the first\ncharacterisation of centralised, decentralised, and federated global platforms,\ngrassroots platforms have been formally defined previously, but using different\nnotions. Here, we prove that their original definition implies that all agents\nare essential, placing grassroots platforms in a distinct class within the\nbroader formal context that includes all global platforms. This work provides\nthe first mathematical framework for classifying any global platform --\nexisting or imagined -- by providing a multiagent atomic-transactions\nspecification of it and determining the cardinality of the minimal set of\nessential agents in the ensuing multiagent protocol. It thus", "AI": {"tldr": "The paper introduces a formal framework\u2014atomic-transactions multiagent transition systems\u2014to model global digital platforms, defines \"essential agents\" (minimal agent sets whose removal breaks communication), and shows counting essential agents partitions platforms into four classes: centralised (1), decentralised (>1 finite), federated (infinite but not universal), and grassroots (universal). It provides formal specifications and correctness proofs for a social-network example and argues grassroots platforms, as previously defined, imply universality of essential agents.", "motivation": "Provide a precise mathematical framework to classify and reason about global digital platforms (servers, p2p systems, federations, grassroots) and to compare architectures using formal properties rather than informal descriptions.", "method": "Define multiagent transition systems with atomic transactions, formalize \"essential agents\", prove that the cardinality of minimal essential-agent sets yields a four-way partition, and instantiate the framework with formal specifications and proofs for a social-network use case; discuss other platform types informally.", "result": "A provable four-class taxonomy of global platforms; formal atomic-transaction specifications for centralised, decentralised, federated, and grassroots social-network variants; proof that earlier grassroots definitions entail that all agents are essential, placing them in a distinct class.", "conclusion": "The framework gives a first systematic mathematical method to classify any global platform by writing a multiagent atomic-transaction specification and computing the minimal essential-agent cardinality; it clarifies and unifies several informal notions and locates grassroots platforms distinctly."}}
{"id": "2511.03293", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03293", "abs": "https://arxiv.org/abs/2511.03293", "authors": ["Hai Huang", "Xuhong Qiang", "Weisheng Zhao", "Chenchen Liu"], "title": "UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM", "comment": "5 pages, 5 figures, under review for IEEE ISCAS", "summary": "Large Language Models (LLMs) are increasingly deployed on edge devices with\nNeural Processing Units (NPUs), yet the decode phase remains memory-intensive,\nlimiting performance. Processing-in-Memory (PIM) offers a promising solution,\nbut co-executing NPU-PIM systems face challenges such as data layout\nmismatches, bandwidth loss, and redundant storage. To address these issues, we\npropose UMDAM, a unified memory-affinity data layout and DRAM address mapping\nscheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,\ntile-based layout and a configurable DRAM mapping strategy to ensure\ncompatibility with NPU computation while maximizing PIM efficiency -- without\nintroducing extra memory overhead or bandwidth loss. Comprehensive evaluations\non OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up\nto 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving\nend-to-end LLM inference efficiency on edge devices.", "AI": {"tldr": "UMDAM is a unified data layout and DRAM address-mapping scheme that aligns NPU and PIM memory layouts (column-major, tile-based + configurable DRAM mapping) so NPU-PIM co-execution avoids layout mismatch, bandwidth loss and redundant storage, achieving up to 3.0x TTFT and 2.18x TTLT speedups on OPT models without extra memory overhead.", "motivation": "LLM decoding on edge devices is memory- bound; NPUs and PIMs have different data layout/access patterns leading to inefficient data movement, bandwidth loss, and duplicated storage when co-executing. A layout and address-mapping scheme that is simultaneously friendly to both NPU computation and PIM access can unlock performance and latency improvements.", "method": "Design a column-major, tile-based memory layout that matches NPU compute locality while enabling efficient PIM operations. Add a configurable DRAM address mapping layer that maps tiles to DRAM banks/rows to maximize PIM bandwidth and avoid bank conflicts, all without extra memory copies or storage overhead. The scheme is applied at data- layout and address-translation time so that NPU and PIM can co-execute directly on shared buffers.", "result": "On a suite of OPT models, UMDAM reduces time-to-first-token (TTFT) by up to 3.0x and time-to-last-token (TTLT) by up to 2.18x, demonstrating substantial end-to-end inference latency improvements for edge LLM decoding workloads.", "conclusion": "UMDAM effectively resolves layout and DRAM mapping mismatches in NPU-PIM co-execution, enabling large latency reductions for LLM decoding on edge devices without additional memory or bandwidth penalty. Future work could extend evaluations to more model families, power/energy metrics, and hardware prototypes."}}
